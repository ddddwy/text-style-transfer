2019-04-14 20:39:25,298 - INFO - collecting all words and their counts
2019-04-14 20:39:25,299 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-14 20:39:25,323 - INFO - collected 793 word types and 500 unique tags from a corpus of 500 examples and 3583 words
2019-04-14 20:39:25,324 - INFO - Loading a fresh vocabulary
2019-04-14 20:39:25,325 - INFO - effective_min_count=5 retains 94 unique words (11% of original 793, drops 699)
2019-04-14 20:39:25,325 - INFO - effective_min_count=5 leaves 2638 word corpus (73% of original 3583, drops 945)
2019-04-14 20:39:25,326 - INFO - deleting the raw counts dictionary of 793 items
2019-04-14 20:39:25,327 - INFO - sample=0.001 downsamples 72 most-common words
2019-04-14 20:39:25,328 - INFO - downsampling leaves estimated 914 word corpus (34.7% of prior 2638)
2019-04-14 20:39:25,329 - INFO - estimated required memory for 94 words and 100 dimensions: 422200 bytes
2019-04-14 20:39:25,329 - INFO - resetting layer weights
2019-04-14 20:39:25,340 - INFO - training model with 3 workers on 94 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-14 20:39:25,346 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 20:39:25,347 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 20:39:25,357 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 20:39:25,357 - INFO - EPOCH - 1 : training on 3583 raw words (1401 effective words) took 0.0s, 122462 effective words/s
2019-04-14 20:39:25,360 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 20:39:25,360 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 20:39:25,370 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 20:39:25,371 - INFO - EPOCH - 2 : training on 3583 raw words (1439 effective words) took 0.0s, 127307 effective words/s
2019-04-14 20:39:25,373 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 20:39:25,374 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 20:39:25,384 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 20:39:25,384 - INFO - EPOCH - 3 : training on 3583 raw words (1407 effective words) took 0.0s, 128798 effective words/s
2019-04-14 20:39:25,387 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 20:39:25,387 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 20:39:25,397 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 20:39:25,398 - INFO - EPOCH - 4 : training on 3583 raw words (1429 effective words) took 0.0s, 130255 effective words/s
2019-04-14 20:39:25,400 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 20:39:25,401 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 20:39:25,411 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 20:39:25,411 - INFO - EPOCH - 5 : training on 3583 raw words (1417 effective words) took 0.0s, 126971 effective words/s
2019-04-14 20:39:25,412 - INFO - training on a 17915 raw words (7093 effective words) took 0.1s, 100032 effective words/s
2019-04-14 20:39:25,412 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-14 20:39:25,418 - INFO - Reading data done!
2019-04-14 20:39:25,600 - INFO - MODEL HAS 10364933 params
2019-04-14 20:39:31,704 - INFO - Computing model performance on validation data ...
2019-04-14 20:39:31,705 - INFO - Finished decoding data: 0/500 ...
2019-04-14 20:39:31,707 - INFO - precomputing L2-norms of doc weight vectors
2019-04-14 20:39:53,273 - INFO - Finished decoding data: 100/500 ...
2019-04-14 20:40:13,947 - INFO - Finished decoding data: 200/500 ...
2019-04-14 20:40:35,470 - INFO - Finished decoding data: 300/500 ...
2019-04-14 20:40:57,485 - INFO - Finished decoding data: 400/500 ...
2019-04-14 20:41:18,697 - INFO - eval_precision: 0.023500
2019-04-14 20:41:18,698 - INFO - eval_recall: 0.037300
2019-04-14 20:41:18,699 - INFO - eval_edit_distance: 7.784000
2019-04-14 20:41:18,700 - INFO - eval_rouge: 0.103959
2019-04-14 21:41:56,414 - INFO - collecting all words and their counts
2019-04-14 21:41:56,417 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-14 21:41:56,441 - INFO - collected 793 word types and 500 unique tags from a corpus of 500 examples and 3583 words
2019-04-14 21:41:56,442 - INFO - Loading a fresh vocabulary
2019-04-14 21:41:56,443 - INFO - effective_min_count=5 retains 94 unique words (11% of original 793, drops 699)
2019-04-14 21:41:56,444 - INFO - effective_min_count=5 leaves 2638 word corpus (73% of original 3583, drops 945)
2019-04-14 21:41:56,445 - INFO - deleting the raw counts dictionary of 793 items
2019-04-14 21:41:56,446 - INFO - sample=0.001 downsamples 72 most-common words
2019-04-14 21:41:56,446 - INFO - downsampling leaves estimated 914 word corpus (34.7% of prior 2638)
2019-04-14 21:41:56,447 - INFO - estimated required memory for 94 words and 100 dimensions: 422200 bytes
2019-04-14 21:41:56,447 - INFO - resetting layer weights
2019-04-14 21:41:56,457 - INFO - training model with 3 workers on 94 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-14 21:41:56,461 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 21:41:56,462 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 21:41:56,471 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 21:41:56,471 - INFO - EPOCH - 1 : training on 3583 raw words (1401 effective words) took 0.0s, 136502 effective words/s
2019-04-14 21:41:56,474 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 21:41:56,474 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 21:41:56,485 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 21:41:56,485 - INFO - EPOCH - 2 : training on 3583 raw words (1439 effective words) took 0.0s, 123518 effective words/s
2019-04-14 21:41:56,488 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 21:41:56,488 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 21:41:56,499 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 21:41:56,499 - INFO - EPOCH - 3 : training on 3583 raw words (1407 effective words) took 0.0s, 121990 effective words/s
2019-04-14 21:41:56,501 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 21:41:56,502 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 21:41:56,511 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 21:41:56,511 - INFO - EPOCH - 4 : training on 3583 raw words (1429 effective words) took 0.0s, 137961 effective words/s
2019-04-14 21:41:56,514 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 21:41:56,515 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 21:41:56,523 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 21:41:56,524 - INFO - EPOCH - 5 : training on 3583 raw words (1417 effective words) took 0.0s, 137783 effective words/s
2019-04-14 21:41:56,524 - INFO - training on a 17915 raw words (7093 effective words) took 0.1s, 106382 effective words/s
2019-04-14 21:41:56,525 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-14 21:41:56,530 - INFO - Reading data done!
2019-04-14 21:41:56,724 - INFO - MODEL HAS 10364933 params
2019-04-14 21:42:04,424 - INFO - Computing model performance on validation data ...
2019-04-14 21:42:04,425 - INFO - Finished decoding data: 0/500 ...
2019-04-14 21:42:04,427 - INFO - precomputing L2-norms of doc weight vectors
2019-04-14 21:42:31,784 - INFO - Finished decoding data: 100/500 ...
2019-04-14 21:42:58,344 - INFO - Finished decoding data: 200/500 ...
2019-04-14 21:43:23,805 - INFO - Finished decoding data: 300/500 ...
2019-04-14 21:43:51,505 - INFO - Finished decoding data: 400/500 ...
2019-04-14 21:44:15,966 - INFO - eval_precision: 0.023857
2019-04-14 21:44:15,967 - INFO - eval_recall: 0.036727
2019-04-14 21:44:15,968 - INFO - eval_edit_distance: 7.656000
2019-04-14 21:44:15,968 - INFO - eval_rouge: 0.113889
2019-04-14 22:40:51,149 - INFO - collecting all words and their counts
2019-04-14 22:40:51,153 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-14 22:40:51,155 - INFO - collected 793 word types and 500 unique tags from a corpus of 500 examples and 3583 words
2019-04-14 22:40:51,156 - INFO - Loading a fresh vocabulary
2019-04-14 22:40:51,157 - INFO - effective_min_count=5 retains 94 unique words (11% of original 793, drops 699)
2019-04-14 22:40:51,158 - INFO - effective_min_count=5 leaves 2638 word corpus (73% of original 3583, drops 945)
2019-04-14 22:40:51,160 - INFO - deleting the raw counts dictionary of 793 items
2019-04-14 22:40:51,160 - INFO - sample=0.001 downsamples 72 most-common words
2019-04-14 22:40:51,161 - INFO - downsampling leaves estimated 914 word corpus (34.7% of prior 2638)
2019-04-14 22:40:51,163 - INFO - estimated required memory for 94 words and 100 dimensions: 422200 bytes
2019-04-14 22:40:51,163 - INFO - resetting layer weights
2019-04-14 22:40:51,176 - INFO - training model with 3 workers on 94 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-14 22:40:51,179 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 22:40:51,182 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 22:40:51,195 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 22:40:51,196 - INFO - EPOCH - 1 : training on 3583 raw words (1401 effective words) took 0.0s, 80616 effective words/s
2019-04-14 22:40:51,199 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 22:40:51,201 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 22:40:51,210 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 22:40:51,211 - INFO - EPOCH - 2 : training on 3583 raw words (1439 effective words) took 0.0s, 117829 effective words/s
2019-04-14 22:40:51,214 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 22:40:51,216 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 22:40:51,227 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 22:40:51,229 - INFO - EPOCH - 3 : training on 3583 raw words (1407 effective words) took 0.0s, 96390 effective words/s
2019-04-14 22:40:51,241 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 22:40:51,242 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 22:40:51,244 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 22:40:51,245 - INFO - EPOCH - 4 : training on 3583 raw words (1429 effective words) took 0.0s, 104136 effective words/s
2019-04-14 22:40:51,256 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-14 22:40:51,258 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-14 22:40:51,260 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-14 22:40:51,262 - INFO - EPOCH - 5 : training on 3583 raw words (1417 effective words) took 0.0s, 100898 effective words/s
2019-04-14 22:40:51,263 - INFO - training on a 17915 raw words (7093 effective words) took 0.1s, 82584 effective words/s
2019-04-14 22:40:51,264 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-14 22:40:51,267 - INFO - Reading data done!
2019-04-14 22:40:51,367 - INFO - MODEL HAS 10364933 params
2019-04-14 22:40:51,413 - INFO - Computing model performance on validation data ...
2019-04-14 22:40:51,414 - INFO - Finished decoding data: 0/500 ...
2019-04-14 22:40:51,417 - INFO - precomputing L2-norms of doc weight vectors
2019-04-14 22:41:19,037 - INFO - Finished decoding data: 100/500 ...
2019-04-14 22:41:46,157 - INFO - Finished decoding data: 200/500 ...
2019-04-14 22:42:12,915 - INFO - Finished decoding data: 300/500 ...
2019-04-14 22:42:38,864 - INFO - Finished decoding data: 400/500 ...
2019-04-14 22:43:06,895 - INFO - eval_precision: 0.019415
2019-04-14 22:43:06,897 - INFO - eval_recall: 0.032622
2019-04-14 22:43:06,898 - INFO - eval_edit_distance: 7.748000
2019-04-14 22:43:06,898 - INFO - eval_rouge: 0.109045
2019-04-15 14:05:32,778 - INFO - collecting all words and their counts
2019-04-15 14:05:32,778 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-15 14:05:32,810 - INFO - collected 793 word types and 500 unique tags from a corpus of 500 examples and 3583 words
2019-04-15 14:05:32,811 - INFO - Loading a fresh vocabulary
2019-04-15 14:05:32,812 - INFO - effective_min_count=5 retains 94 unique words (11% of original 793, drops 699)
2019-04-15 14:05:32,812 - INFO - effective_min_count=5 leaves 2638 word corpus (73% of original 3583, drops 945)
2019-04-15 14:05:32,813 - INFO - deleting the raw counts dictionary of 793 items
2019-04-15 14:05:32,814 - INFO - sample=0.001 downsamples 72 most-common words
2019-04-15 14:05:32,815 - INFO - downsampling leaves estimated 914 word corpus (34.7% of prior 2638)
2019-04-15 14:05:32,816 - INFO - estimated required memory for 94 words and 100 dimensions: 422200 bytes
2019-04-15 14:05:32,816 - INFO - resetting layer weights
2019-04-15 14:05:32,826 - INFO - training model with 3 workers on 94 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-15 14:05:32,829 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 14:05:32,830 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 14:05:32,842 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 14:05:32,843 - INFO - EPOCH - 1 : training on 3583 raw words (1401 effective words) took 0.0s, 104091 effective words/s
2019-04-15 14:05:32,845 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 14:05:32,846 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 14:05:32,855 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 14:05:32,856 - INFO - EPOCH - 2 : training on 3583 raw words (1439 effective words) took 0.0s, 131833 effective words/s
2019-04-15 14:05:32,859 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 14:05:32,860 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 14:05:32,868 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 14:05:32,869 - INFO - EPOCH - 3 : training on 3583 raw words (1407 effective words) took 0.0s, 127699 effective words/s
2019-04-15 14:05:32,872 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 14:05:32,873 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 14:05:32,882 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 14:05:32,882 - INFO - EPOCH - 4 : training on 3583 raw words (1429 effective words) took 0.0s, 126822 effective words/s
2019-04-15 14:05:32,885 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 14:05:32,886 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 14:05:32,895 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 14:05:32,896 - INFO - EPOCH - 5 : training on 3583 raw words (1417 effective words) took 0.0s, 125949 effective words/s
2019-04-15 14:05:32,896 - INFO - training on a 17915 raw words (7093 effective words) took 0.1s, 102866 effective words/s
2019-04-15 14:05:32,897 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-15 14:05:32,902 - INFO - Reading data done!
2019-04-15 14:05:33,101 - INFO - MODEL HAS 10364933 params
2019-04-15 14:05:39,818 - INFO - Computing model performance on validation data ...
2019-04-15 14:05:39,818 - INFO - Finished decoding data: 0/500 ...
2019-04-15 14:05:39,821 - INFO - precomputing L2-norms of doc weight vectors
2019-04-15 14:05:56,600 - INFO - Finished decoding data: 100/500 ...
2019-04-15 14:06:16,670 - INFO - Finished decoding data: 200/500 ...
2019-04-15 14:06:36,946 - INFO - Finished decoding data: 300/500 ...
2019-04-15 14:06:56,892 - INFO - Finished decoding data: 400/500 ...
2019-04-15 14:07:15,943 - INFO - eval_precision: 0.010862
2019-04-15 14:07:15,944 - INFO - eval_recall: 0.013926
2019-04-15 14:07:15,945 - INFO - eval_edit_distance: 7.660000
2019-04-15 14:07:15,945 - INFO - eval_rouge: 0.112123
2019-04-15 17:00:01,954 - INFO - collecting all words and their counts
2019-04-15 17:00:01,955 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-15 17:00:01,987 - INFO - collected 793 word types and 500 unique tags from a corpus of 500 examples and 3583 words
2019-04-15 17:00:01,987 - INFO - Loading a fresh vocabulary
2019-04-15 17:00:01,988 - INFO - effective_min_count=5 retains 94 unique words (11% of original 793, drops 699)
2019-04-15 17:00:01,989 - INFO - effective_min_count=5 leaves 2638 word corpus (73% of original 3583, drops 945)
2019-04-15 17:00:01,990 - INFO - deleting the raw counts dictionary of 793 items
2019-04-15 17:00:01,991 - INFO - sample=0.001 downsamples 72 most-common words
2019-04-15 17:00:01,991 - INFO - downsampling leaves estimated 914 word corpus (34.7% of prior 2638)
2019-04-15 17:00:01,992 - INFO - estimated required memory for 94 words and 100 dimensions: 422200 bytes
2019-04-15 17:00:01,993 - INFO - resetting layer weights
2019-04-15 17:00:02,003 - INFO - training model with 3 workers on 94 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-15 17:00:02,009 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 17:00:02,009 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 17:00:02,019 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 17:00:02,019 - INFO - EPOCH - 1 : training on 3583 raw words (1401 effective words) took 0.0s, 130154 effective words/s
2019-04-15 17:00:02,022 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 17:00:02,023 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 17:00:02,032 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 17:00:02,033 - INFO - EPOCH - 2 : training on 3583 raw words (1439 effective words) took 0.0s, 126035 effective words/s
2019-04-15 17:00:02,036 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 17:00:02,036 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 17:00:02,045 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 17:00:02,046 - INFO - EPOCH - 3 : training on 3583 raw words (1407 effective words) took 0.0s, 130334 effective words/s
2019-04-15 17:00:02,049 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 17:00:02,050 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 17:00:02,059 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 17:00:02,060 - INFO - EPOCH - 4 : training on 3583 raw words (1429 effective words) took 0.0s, 127052 effective words/s
2019-04-15 17:00:02,063 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 17:00:02,063 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 17:00:02,073 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 17:00:02,073 - INFO - EPOCH - 5 : training on 3583 raw words (1417 effective words) took 0.0s, 129895 effective words/s
2019-04-15 17:00:02,074 - INFO - training on a 17915 raw words (7093 effective words) took 0.1s, 104264 effective words/s
2019-04-15 17:00:02,074 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-15 17:00:02,079 - INFO - Reading data done!
2019-04-15 17:00:02,279 - INFO - MODEL HAS 10364933 params
2019-04-15 17:00:09,541 - INFO - Computing model performance on validation data ...
2019-04-15 17:00:09,542 - INFO - Finished decoding data: 0/500 ...
2019-04-15 17:00:09,543 - INFO - precomputing L2-norms of doc weight vectors
2019-04-15 17:00:29,608 - INFO - Finished decoding data: 100/500 ...
2019-04-15 17:00:50,042 - INFO - Finished decoding data: 200/500 ...
2019-04-15 17:01:09,950 - INFO - Finished decoding data: 300/500 ...
2019-04-15 17:01:29,897 - INFO - Finished decoding data: 400/500 ...
2019-04-15 17:01:47,935 - INFO - eval_precision: 0.012003
2019-04-15 17:01:47,936 - INFO - eval_recall: 0.025720
2019-04-15 17:01:47,937 - INFO - eval_edit_distance: 7.260000
2019-04-15 17:01:47,937 - INFO - eval_rouge: 0.147939
2019-04-15 19:33:48,567 - INFO - collecting all words and their counts
2019-04-15 19:33:48,567 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-15 19:33:48,598 - INFO - collected 793 word types and 500 unique tags from a corpus of 500 examples and 3583 words
2019-04-15 19:33:48,599 - INFO - Loading a fresh vocabulary
2019-04-15 19:33:48,600 - INFO - effective_min_count=5 retains 94 unique words (11% of original 793, drops 699)
2019-04-15 19:33:48,601 - INFO - effective_min_count=5 leaves 2638 word corpus (73% of original 3583, drops 945)
2019-04-15 19:33:48,602 - INFO - deleting the raw counts dictionary of 793 items
2019-04-15 19:33:48,603 - INFO - sample=0.001 downsamples 72 most-common words
2019-04-15 19:33:48,603 - INFO - downsampling leaves estimated 914 word corpus (34.7% of prior 2638)
2019-04-15 19:33:48,604 - INFO - estimated required memory for 94 words and 100 dimensions: 422200 bytes
2019-04-15 19:33:48,605 - INFO - resetting layer weights
2019-04-15 19:33:48,615 - INFO - training model with 3 workers on 94 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-15 19:33:48,618 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:33:48,619 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:33:48,631 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:33:48,632 - INFO - EPOCH - 1 : training on 3583 raw words (1401 effective words) took 0.0s, 102347 effective words/s
2019-04-15 19:33:48,634 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:33:48,635 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:33:48,645 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:33:48,646 - INFO - EPOCH - 2 : training on 3583 raw words (1439 effective words) took 0.0s, 122204 effective words/s
2019-04-15 19:33:48,648 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:33:48,649 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:33:48,659 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:33:48,660 - INFO - EPOCH - 3 : training on 3583 raw words (1407 effective words) took 0.0s, 123312 effective words/s
2019-04-15 19:33:48,662 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:33:48,663 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:33:48,672 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:33:48,673 - INFO - EPOCH - 4 : training on 3583 raw words (1429 effective words) took 0.0s, 128829 effective words/s
2019-04-15 19:33:48,676 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:33:48,677 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:33:48,686 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:33:48,687 - INFO - EPOCH - 5 : training on 3583 raw words (1417 effective words) took 0.0s, 128335 effective words/s
2019-04-15 19:33:48,687 - INFO - training on a 17915 raw words (7093 effective words) took 0.1s, 99765 effective words/s
2019-04-15 19:33:48,688 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-15 19:33:48,693 - INFO - Reading data done!
2019-04-15 19:33:48,885 - INFO - MODEL HAS 10364933 params
2019-04-15 19:33:55,609 - INFO - Computing model performance on validation data ...
2019-04-15 19:33:55,610 - INFO - Finished decoding data: 0/500 ...
2019-04-15 19:33:55,611 - INFO - precomputing L2-norms of doc weight vectors
2019-04-15 19:35:05,897 - INFO - collecting all words and their counts
2019-04-15 19:35:05,899 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-15 19:35:05,902 - INFO - collected 793 word types and 500 unique tags from a corpus of 500 examples and 3583 words
2019-04-15 19:35:05,903 - INFO - Loading a fresh vocabulary
2019-04-15 19:35:05,904 - INFO - effective_min_count=5 retains 94 unique words (11% of original 793, drops 699)
2019-04-15 19:35:05,905 - INFO - effective_min_count=5 leaves 2638 word corpus (73% of original 3583, drops 945)
2019-04-15 19:35:05,906 - INFO - deleting the raw counts dictionary of 793 items
2019-04-15 19:35:05,907 - INFO - sample=0.001 downsamples 72 most-common words
2019-04-15 19:35:05,908 - INFO - downsampling leaves estimated 914 word corpus (34.7% of prior 2638)
2019-04-15 19:35:05,909 - INFO - estimated required memory for 94 words and 100 dimensions: 422200 bytes
2019-04-15 19:35:05,909 - INFO - resetting layer weights
2019-04-15 19:35:05,920 - INFO - training model with 3 workers on 94 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-15 19:35:05,928 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:35:05,930 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:35:05,945 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:35:05,946 - INFO - EPOCH - 1 : training on 3583 raw words (1401 effective words) took 0.0s, 79068 effective words/s
2019-04-15 19:35:05,949 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:35:05,951 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:35:05,961 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:35:05,962 - INFO - EPOCH - 2 : training on 3583 raw words (1439 effective words) took 0.0s, 108398 effective words/s
2019-04-15 19:35:05,966 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:35:05,968 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:35:05,978 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:35:05,980 - INFO - EPOCH - 3 : training on 3583 raw words (1407 effective words) took 0.0s, 103206 effective words/s
2019-04-15 19:35:05,983 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:35:05,985 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:35:05,995 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:35:05,997 - INFO - EPOCH - 4 : training on 3583 raw words (1429 effective words) took 0.0s, 99336 effective words/s
2019-04-15 19:35:06,000 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:35:06,002 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:35:06,012 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:35:06,013 - INFO - EPOCH - 5 : training on 3583 raw words (1417 effective words) took 0.0s, 110877 effective words/s
2019-04-15 19:35:06,014 - INFO - training on a 17915 raw words (7093 effective words) took 0.1s, 79427 effective words/s
2019-04-15 19:35:06,015 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-15 19:35:06,021 - INFO - Reading data done!
2019-04-15 19:35:06,125 - INFO - MODEL HAS 10364933 params
2019-04-15 19:35:06,178 - INFO - Computing model performance on validation data ...
2019-04-15 19:35:06,180 - INFO - Finished decoding data: 0/500 ...
2019-04-15 19:35:06,182 - INFO - precomputing L2-norms of doc weight vectors
2019-04-15 19:41:06,118 - INFO - collecting all words and their counts
2019-04-15 19:41:06,119 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-15 19:41:06,149 - INFO - collected 793 word types and 500 unique tags from a corpus of 500 examples and 3583 words
2019-04-15 19:41:06,150 - INFO - Loading a fresh vocabulary
2019-04-15 19:41:06,151 - INFO - effective_min_count=5 retains 94 unique words (11% of original 793, drops 699)
2019-04-15 19:41:06,151 - INFO - effective_min_count=5 leaves 2638 word corpus (73% of original 3583, drops 945)
2019-04-15 19:41:06,152 - INFO - deleting the raw counts dictionary of 793 items
2019-04-15 19:41:06,153 - INFO - sample=0.001 downsamples 72 most-common words
2019-04-15 19:41:06,154 - INFO - downsampling leaves estimated 914 word corpus (34.7% of prior 2638)
2019-04-15 19:41:06,155 - INFO - estimated required memory for 94 words and 100 dimensions: 422200 bytes
2019-04-15 19:41:06,155 - INFO - resetting layer weights
2019-04-15 19:41:06,166 - INFO - training model with 3 workers on 94 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-15 19:41:06,171 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:41:06,172 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:41:06,181 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:41:06,182 - INFO - EPOCH - 1 : training on 3583 raw words (1401 effective words) took 0.0s, 132335 effective words/s
2019-04-15 19:41:06,184 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:41:06,185 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:41:06,194 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:41:06,195 - INFO - EPOCH - 2 : training on 3583 raw words (1439 effective words) took 0.0s, 131206 effective words/s
2019-04-15 19:41:06,197 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:41:06,198 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:41:06,207 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:41:06,208 - INFO - EPOCH - 3 : training on 3583 raw words (1407 effective words) took 0.0s, 124264 effective words/s
2019-04-15 19:41:06,211 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:41:06,212 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:41:06,221 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:41:06,222 - INFO - EPOCH - 4 : training on 3583 raw words (1429 effective words) took 0.0s, 123786 effective words/s
2019-04-15 19:41:06,224 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:41:06,225 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:41:06,234 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:41:06,235 - INFO - EPOCH - 5 : training on 3583 raw words (1417 effective words) took 0.0s, 128900 effective words/s
2019-04-15 19:41:06,235 - INFO - training on a 17915 raw words (7093 effective words) took 0.1s, 103255 effective words/s
2019-04-15 19:41:06,236 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-15 19:41:06,241 - INFO - Reading data done!
2019-04-15 19:41:06,440 - INFO - MODEL HAS 10364933 params
2019-04-15 19:41:13,210 - INFO - Computing model performance on validation data ...
2019-04-15 19:41:13,211 - INFO - Finished decoding data: 0/500 ...
2019-04-15 19:41:13,212 - INFO - precomputing L2-norms of doc weight vectors
2019-04-15 19:44:23,835 - INFO - collecting all words and their counts
2019-04-15 19:44:23,836 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-15 19:44:23,838 - INFO - collected 793 word types and 500 unique tags from a corpus of 500 examples and 3583 words
2019-04-15 19:44:23,839 - INFO - Loading a fresh vocabulary
2019-04-15 19:44:23,841 - INFO - effective_min_count=5 retains 94 unique words (11% of original 793, drops 699)
2019-04-15 19:44:23,842 - INFO - effective_min_count=5 leaves 2638 word corpus (73% of original 3583, drops 945)
2019-04-15 19:44:23,843 - INFO - deleting the raw counts dictionary of 793 items
2019-04-15 19:44:23,844 - INFO - sample=0.001 downsamples 72 most-common words
2019-04-15 19:44:23,844 - INFO - downsampling leaves estimated 914 word corpus (34.7% of prior 2638)
2019-04-15 19:44:23,846 - INFO - estimated required memory for 94 words and 100 dimensions: 422200 bytes
2019-04-15 19:44:23,846 - INFO - resetting layer weights
2019-04-15 19:44:23,858 - INFO - training model with 3 workers on 94 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-15 19:44:23,866 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:44:23,868 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:44:23,878 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:44:23,879 - INFO - EPOCH - 1 : training on 3583 raw words (1401 effective words) took 0.0s, 108631 effective words/s
2019-04-15 19:44:23,882 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:44:23,884 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:44:23,894 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:44:23,895 - INFO - EPOCH - 2 : training on 3583 raw words (1439 effective words) took 0.0s, 110663 effective words/s
2019-04-15 19:44:23,899 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:44:23,900 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:44:23,910 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:44:23,911 - INFO - EPOCH - 3 : training on 3583 raw words (1407 effective words) took 0.0s, 110160 effective words/s
2019-04-15 19:44:23,915 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:44:23,917 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:44:23,926 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:44:23,928 - INFO - EPOCH - 4 : training on 3583 raw words (1429 effective words) took 0.0s, 109665 effective words/s
2019-04-15 19:44:23,930 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:44:23,932 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:44:23,943 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:44:23,944 - INFO - EPOCH - 5 : training on 3583 raw words (1417 effective words) took 0.0s, 104101 effective words/s
2019-04-15 19:44:23,945 - INFO - training on a 17915 raw words (7093 effective words) took 0.1s, 82645 effective words/s
2019-04-15 19:44:23,945 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-15 19:44:23,952 - INFO - Reading data done!
2019-04-15 19:44:24,053 - INFO - MODEL HAS 10364933 params
2019-04-15 19:44:24,101 - INFO - Computing model performance on validation data ...
2019-04-15 19:44:24,102 - INFO - Finished decoding data: 0/500 ...
2019-04-15 19:44:24,105 - INFO - precomputing L2-norms of doc weight vectors
2019-04-15 19:48:42,810 - INFO - collecting all words and their counts
2019-04-15 19:48:42,811 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-15 19:48:42,813 - INFO - collected 793 word types and 500 unique tags from a corpus of 500 examples and 3583 words
2019-04-15 19:48:42,814 - INFO - Loading a fresh vocabulary
2019-04-15 19:48:42,815 - INFO - effective_min_count=5 retains 94 unique words (11% of original 793, drops 699)
2019-04-15 19:48:42,815 - INFO - effective_min_count=5 leaves 2638 word corpus (73% of original 3583, drops 945)
2019-04-15 19:48:42,816 - INFO - deleting the raw counts dictionary of 793 items
2019-04-15 19:48:42,817 - INFO - sample=0.001 downsamples 72 most-common words
2019-04-15 19:48:42,818 - INFO - downsampling leaves estimated 914 word corpus (34.7% of prior 2638)
2019-04-15 19:48:42,818 - INFO - estimated required memory for 94 words and 100 dimensions: 422200 bytes
2019-04-15 19:48:42,819 - INFO - resetting layer weights
2019-04-15 19:48:42,829 - INFO - training model with 3 workers on 94 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-15 19:48:42,835 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:48:42,836 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:48:42,845 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:48:42,846 - INFO - EPOCH - 1 : training on 3583 raw words (1401 effective words) took 0.0s, 133294 effective words/s
2019-04-15 19:48:42,848 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:48:42,849 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:48:42,858 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:48:42,859 - INFO - EPOCH - 2 : training on 3583 raw words (1439 effective words) took 0.0s, 138263 effective words/s
2019-04-15 19:48:42,862 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:48:42,862 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:48:42,871 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:48:42,872 - INFO - EPOCH - 3 : training on 3583 raw words (1407 effective words) took 0.0s, 135104 effective words/s
2019-04-15 19:48:42,874 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:48:42,875 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:48:42,884 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:48:42,884 - INFO - EPOCH - 4 : training on 3583 raw words (1429 effective words) took 0.0s, 136270 effective words/s
2019-04-15 19:48:42,887 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:48:42,888 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:48:42,897 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:48:42,898 - INFO - EPOCH - 5 : training on 3583 raw words (1417 effective words) took 0.0s, 132713 effective words/s
2019-04-15 19:48:42,898 - INFO - training on a 17915 raw words (7093 effective words) took 0.1s, 104432 effective words/s
2019-04-15 19:48:42,899 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-15 19:48:42,904 - INFO - Reading data done!
2019-04-15 19:48:43,101 - INFO - MODEL HAS 10364933 params
2019-04-15 19:48:50,432 - INFO - Computing model performance on validation data ...
2019-04-15 19:48:50,433 - INFO - Finished decoding data: 0/500 ...
2019-04-15 19:48:50,435 - INFO - precomputing L2-norms of doc weight vectors
2019-04-15 19:51:38,199 - INFO - collecting all words and their counts
2019-04-15 19:51:38,200 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-15 19:51:38,202 - INFO - collected 793 word types and 500 unique tags from a corpus of 500 examples and 3583 words
2019-04-15 19:51:38,203 - INFO - Loading a fresh vocabulary
2019-04-15 19:51:38,204 - INFO - effective_min_count=5 retains 94 unique words (11% of original 793, drops 699)
2019-04-15 19:51:38,204 - INFO - effective_min_count=5 leaves 2638 word corpus (73% of original 3583, drops 945)
2019-04-15 19:51:38,205 - INFO - deleting the raw counts dictionary of 793 items
2019-04-15 19:51:38,206 - INFO - sample=0.001 downsamples 72 most-common words
2019-04-15 19:51:38,207 - INFO - downsampling leaves estimated 914 word corpus (34.7% of prior 2638)
2019-04-15 19:51:38,207 - INFO - estimated required memory for 94 words and 100 dimensions: 422200 bytes
2019-04-15 19:51:38,208 - INFO - resetting layer weights
2019-04-15 19:51:38,219 - INFO - training model with 3 workers on 94 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-15 19:51:38,224 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:51:38,225 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:51:38,234 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:51:38,235 - INFO - EPOCH - 1 : training on 3583 raw words (1401 effective words) took 0.0s, 132968 effective words/s
2019-04-15 19:51:38,238 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:51:38,239 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:51:38,247 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:51:38,248 - INFO - EPOCH - 2 : training on 3583 raw words (1439 effective words) took 0.0s, 132102 effective words/s
2019-04-15 19:51:38,251 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:51:38,252 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:51:38,260 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:51:38,261 - INFO - EPOCH - 3 : training on 3583 raw words (1407 effective words) took 0.0s, 134820 effective words/s
2019-04-15 19:51:38,263 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:51:38,264 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:51:38,273 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:51:38,274 - INFO - EPOCH - 4 : training on 3583 raw words (1429 effective words) took 0.0s, 129660 effective words/s
2019-04-15 19:51:38,277 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:51:38,278 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:51:38,286 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:51:38,287 - INFO - EPOCH - 5 : training on 3583 raw words (1417 effective words) took 0.0s, 135240 effective words/s
2019-04-15 19:51:38,288 - INFO - training on a 17915 raw words (7093 effective words) took 0.1s, 104463 effective words/s
2019-04-15 19:51:38,288 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-15 19:51:38,293 - INFO - Reading data done!
2019-04-15 19:51:38,502 - INFO - MODEL HAS 10364933 params
2019-04-15 19:51:46,368 - INFO - Computing model performance on validation data ...
2019-04-15 19:51:46,368 - INFO - Finished decoding data: 0/500 ...
2019-04-15 19:51:46,396 - INFO - precomputing L2-norms of doc weight vectors
2019-04-15 19:53:30,503 - INFO - collecting all words and their counts
2019-04-15 19:53:30,505 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-15 19:53:30,507 - INFO - collected 795 word types and 500 unique tags from a corpus of 500 examples and 3582 words
2019-04-15 19:53:30,508 - INFO - Loading a fresh vocabulary
2019-04-15 19:53:30,509 - INFO - effective_min_count=5 retains 90 unique words (11% of original 795, drops 705)
2019-04-15 19:53:30,509 - INFO - effective_min_count=5 leaves 2601 word corpus (72% of original 3582, drops 981)
2019-04-15 19:53:30,510 - INFO - deleting the raw counts dictionary of 795 items
2019-04-15 19:53:30,511 - INFO - sample=0.001 downsamples 70 most-common words
2019-04-15 19:53:30,512 - INFO - downsampling leaves estimated 874 word corpus (33.6% of prior 2601)
2019-04-15 19:53:30,513 - INFO - estimated required memory for 90 words and 100 dimensions: 417000 bytes
2019-04-15 19:53:30,513 - INFO - resetting layer weights
2019-04-15 19:53:30,524 - INFO - training model with 3 workers on 90 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-15 19:53:30,528 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:53:30,529 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:53:30,539 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:53:30,540 - INFO - EPOCH - 1 : training on 3582 raw words (1398 effective words) took 0.0s, 125325 effective words/s
2019-04-15 19:53:30,542 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:53:30,543 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:53:30,552 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:53:30,553 - INFO - EPOCH - 2 : training on 3582 raw words (1366 effective words) took 0.0s, 124080 effective words/s
2019-04-15 19:53:30,555 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:53:30,556 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:53:30,565 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:53:30,566 - INFO - EPOCH - 3 : training on 3582 raw words (1369 effective words) took 0.0s, 125831 effective words/s
2019-04-15 19:53:30,568 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:53:30,569 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:53:30,578 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:53:30,579 - INFO - EPOCH - 4 : training on 3582 raw words (1400 effective words) took 0.0s, 128122 effective words/s
2019-04-15 19:53:30,581 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:53:30,582 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:53:30,591 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:53:30,592 - INFO - EPOCH - 5 : training on 3582 raw words (1394 effective words) took 0.0s, 132699 effective words/s
2019-04-15 19:53:30,592 - INFO - training on a 17910 raw words (6927 effective words) took 0.1s, 102189 effective words/s
2019-04-15 19:53:30,593 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-15 19:53:30,598 - INFO - Reading data done!
2019-04-15 19:53:30,795 - INFO - MODEL HAS 10364933 params
2019-04-15 19:53:37,691 - INFO - Computing model performance on validation data ...
2019-04-15 19:53:37,692 - INFO - Finished decoding data: 0/500 ...
2019-04-15 19:53:37,694 - INFO - precomputing L2-norms of doc weight vectors
2019-04-15 19:55:14,789 - INFO - collecting all words and their counts
2019-04-15 19:55:14,790 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-15 19:55:14,792 - INFO - collected 813 word types and 500 unique tags from a corpus of 500 examples and 3585 words
2019-04-15 19:55:14,792 - INFO - Loading a fresh vocabulary
2019-04-15 19:55:14,793 - INFO - effective_min_count=5 retains 90 unique words (11% of original 813, drops 723)
2019-04-15 19:55:14,794 - INFO - effective_min_count=5 leaves 2582 word corpus (72% of original 3585, drops 1003)
2019-04-15 19:55:14,795 - INFO - deleting the raw counts dictionary of 813 items
2019-04-15 19:55:14,796 - INFO - sample=0.001 downsamples 69 most-common words
2019-04-15 19:55:14,796 - INFO - downsampling leaves estimated 869 word corpus (33.7% of prior 2582)
2019-04-15 19:55:14,797 - INFO - estimated required memory for 90 words and 100 dimensions: 417000 bytes
2019-04-15 19:55:14,797 - INFO - resetting layer weights
2019-04-15 19:55:14,808 - INFO - training model with 3 workers on 90 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-15 19:55:14,811 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:55:14,812 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:55:14,824 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:55:14,825 - INFO - EPOCH - 1 : training on 3585 raw words (1368 effective words) took 0.0s, 100473 effective words/s
2019-04-15 19:55:14,828 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:55:14,829 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:55:14,838 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:55:14,839 - INFO - EPOCH - 2 : training on 3585 raw words (1402 effective words) took 0.0s, 126309 effective words/s
2019-04-15 19:55:14,841 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:55:14,842 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:55:14,852 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:55:14,853 - INFO - EPOCH - 3 : training on 3585 raw words (1348 effective words) took 0.0s, 118466 effective words/s
2019-04-15 19:55:14,855 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:55:14,856 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:55:14,866 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:55:14,867 - INFO - EPOCH - 4 : training on 3585 raw words (1381 effective words) took 0.0s, 118426 effective words/s
2019-04-15 19:55:14,869 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 19:55:14,870 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 19:55:14,880 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 19:55:14,880 - INFO - EPOCH - 5 : training on 3585 raw words (1388 effective words) took 0.0s, 124441 effective words/s
2019-04-15 19:55:14,881 - INFO - training on a 17925 raw words (6887 effective words) took 0.1s, 95046 effective words/s
2019-04-15 19:55:14,881 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-15 19:55:14,886 - INFO - Reading data done!
2019-04-15 19:55:15,089 - INFO - MODEL HAS 10364933 params
2019-04-15 19:55:21,853 - INFO - Computing model performance on validation data ...
2019-04-15 19:55:21,854 - INFO - Finished decoding data: 0/500 ...
2019-04-15 19:55:21,856 - INFO - precomputing L2-norms of doc weight vectors
2019-04-15 20:12:35,296 - INFO - collecting all words and their counts
2019-04-15 20:12:35,298 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-15 20:12:35,300 - INFO - collected 813 word types and 500 unique tags from a corpus of 500 examples and 3585 words
2019-04-15 20:12:35,301 - INFO - Loading a fresh vocabulary
2019-04-15 20:12:35,302 - INFO - effective_min_count=5 retains 90 unique words (11% of original 813, drops 723)
2019-04-15 20:12:35,303 - INFO - effective_min_count=5 leaves 2582 word corpus (72% of original 3585, drops 1003)
2019-04-15 20:12:35,304 - INFO - deleting the raw counts dictionary of 813 items
2019-04-15 20:12:35,305 - INFO - sample=0.001 downsamples 69 most-common words
2019-04-15 20:12:35,306 - INFO - downsampling leaves estimated 869 word corpus (33.7% of prior 2582)
2019-04-15 20:12:35,307 - INFO - estimated required memory for 90 words and 100 dimensions: 417000 bytes
2019-04-15 20:12:35,308 - INFO - resetting layer weights
2019-04-15 20:12:35,319 - INFO - training model with 3 workers on 90 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-15 20:12:35,322 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 20:12:35,328 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 20:12:35,339 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 20:12:35,340 - INFO - EPOCH - 1 : training on 3585 raw words (1368 effective words) took 0.0s, 73650 effective words/s
2019-04-15 20:12:35,344 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 20:12:35,346 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 20:12:35,355 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 20:12:35,356 - INFO - EPOCH - 2 : training on 3585 raw words (1402 effective words) took 0.0s, 110898 effective words/s
2019-04-15 20:12:35,359 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 20:12:35,361 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 20:12:35,371 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 20:12:35,372 - INFO - EPOCH - 3 : training on 3585 raw words (1348 effective words) took 0.0s, 101716 effective words/s
2019-04-15 20:12:35,375 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 20:12:35,377 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 20:12:35,387 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 20:12:35,388 - INFO - EPOCH - 4 : training on 3585 raw words (1381 effective words) took 0.0s, 101501 effective words/s
2019-04-15 20:12:35,392 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 20:12:35,393 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 20:12:35,403 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 20:12:35,405 - INFO - EPOCH - 5 : training on 3585 raw words (1388 effective words) took 0.0s, 100366 effective words/s
2019-04-15 20:12:35,405 - INFO - training on a 17925 raw words (6887 effective words) took 0.1s, 80232 effective words/s
2019-04-15 20:12:35,406 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-15 20:12:35,413 - INFO - Reading data done!
2019-04-15 20:12:35,518 - INFO - MODEL HAS 10364933 params
2019-04-15 20:12:35,564 - INFO - Computing model performance on validation data ...
2019-04-15 20:12:35,565 - INFO - Finished decoding data: 0/500 ...
2019-04-15 20:12:35,568 - INFO - precomputing L2-norms of doc weight vectors
2019-04-15 20:34:55,374 - INFO - collecting all words and their counts
2019-04-15 20:34:55,377 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-15 20:34:55,380 - INFO - collected 813 word types and 500 unique tags from a corpus of 500 examples and 3585 words
2019-04-15 20:34:55,381 - INFO - Loading a fresh vocabulary
2019-04-15 20:34:55,383 - INFO - effective_min_count=5 retains 90 unique words (11% of original 813, drops 723)
2019-04-15 20:34:55,384 - INFO - effective_min_count=5 leaves 2582 word corpus (72% of original 3585, drops 1003)
2019-04-15 20:34:55,386 - INFO - deleting the raw counts dictionary of 813 items
2019-04-15 20:34:55,387 - INFO - sample=0.001 downsamples 69 most-common words
2019-04-15 20:34:55,388 - INFO - downsampling leaves estimated 869 word corpus (33.7% of prior 2582)
2019-04-15 20:34:55,390 - INFO - estimated required memory for 90 words and 100 dimensions: 417000 bytes
2019-04-15 20:34:55,391 - INFO - resetting layer weights
2019-04-15 20:34:55,402 - INFO - training model with 3 workers on 90 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-15 20:34:55,408 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 20:34:55,411 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 20:34:55,428 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 20:34:55,430 - INFO - EPOCH - 1 : training on 3585 raw words (1368 effective words) took 0.0s, 63577 effective words/s
2019-04-15 20:34:55,433 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 20:34:55,435 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 20:34:55,448 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 20:34:55,449 - INFO - EPOCH - 2 : training on 3585 raw words (1402 effective words) took 0.0s, 85659 effective words/s
2019-04-15 20:34:55,454 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 20:34:55,456 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 20:34:55,467 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 20:34:55,469 - INFO - EPOCH - 3 : training on 3585 raw words (1348 effective words) took 0.0s, 87355 effective words/s
2019-04-15 20:34:55,473 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 20:34:55,476 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 20:34:55,487 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 20:34:55,488 - INFO - EPOCH - 4 : training on 3585 raw words (1381 effective words) took 0.0s, 89655 effective words/s
2019-04-15 20:34:55,493 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-15 20:34:55,495 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-15 20:34:55,506 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-15 20:34:55,509 - INFO - EPOCH - 5 : training on 3585 raw words (1388 effective words) took 0.0s, 88419 effective words/s
2019-04-15 20:34:55,510 - INFO - training on a 17925 raw words (6887 effective words) took 0.1s, 64753 effective words/s
2019-04-15 20:34:55,511 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-15 20:34:55,519 - INFO - Reading data done!
2019-04-15 20:34:55,617 - INFO - MODEL HAS 10364933 params
2019-04-15 20:34:55,657 - INFO - Computing model performance on validation data ...
2019-04-15 20:34:55,659 - INFO - Finished decoding data: 0/500 ...
2019-04-15 20:34:55,662 - INFO - precomputing L2-norms of doc weight vectors
2019-04-16 16:13:55,463 - INFO - collecting all words and their counts
2019-04-16 16:13:55,466 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-04-16 16:13:55,469 - INFO - collected 813 word types and 500 unique tags from a corpus of 500 examples and 3585 words
2019-04-16 16:13:55,471 - INFO - Loading a fresh vocabulary
2019-04-16 16:13:55,473 - INFO - effective_min_count=5 retains 90 unique words (11% of original 813, drops 723)
2019-04-16 16:13:55,475 - INFO - effective_min_count=5 leaves 2582 word corpus (72% of original 3585, drops 1003)
2019-04-16 16:13:55,477 - INFO - deleting the raw counts dictionary of 813 items
2019-04-16 16:13:55,479 - INFO - sample=0.001 downsamples 69 most-common words
2019-04-16 16:13:55,481 - INFO - downsampling leaves estimated 869 word corpus (33.7% of prior 2582)
2019-04-16 16:13:55,483 - INFO - estimated required memory for 90 words and 100 dimensions: 417000 bytes
2019-04-16 16:13:55,485 - INFO - resetting layer weights
2019-04-16 16:13:55,493 - INFO - training model with 3 workers on 90 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-04-16 16:13:55,506 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-16 16:13:55,508 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-16 16:13:55,509 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-16 16:13:55,509 - INFO - EPOCH - 1 : training on 3585 raw words (1368 effective words) took 0.0s, 116888 effective words/s
2019-04-16 16:13:55,522 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-16 16:13:55,524 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-16 16:13:55,525 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-16 16:13:55,526 - INFO - EPOCH - 2 : training on 3585 raw words (1402 effective words) took 0.0s, 124327 effective words/s
2019-04-16 16:13:55,540 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-16 16:13:55,541 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-16 16:13:55,542 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-16 16:13:55,545 - INFO - EPOCH - 3 : training on 3585 raw words (1348 effective words) took 0.0s, 98231 effective words/s
2019-04-16 16:13:55,556 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-16 16:13:55,558 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-16 16:13:55,559 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-16 16:13:55,561 - INFO - EPOCH - 4 : training on 3585 raw words (1381 effective words) took 0.0s, 109523 effective words/s
2019-04-16 16:13:55,573 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-04-16 16:13:55,575 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-04-16 16:13:55,576 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-04-16 16:13:55,576 - INFO - EPOCH - 5 : training on 3585 raw words (1388 effective words) took 0.0s, 123064 effective words/s
2019-04-16 16:13:55,579 - INFO - training on a 17925 raw words (6887 effective words) took 0.1s, 81922 effective words/s
2019-04-16 16:13:55,580 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-04-16 16:13:55,582 - INFO - Reading data done!
2019-04-16 16:13:55,791 - INFO - MODEL HAS 10364933 params
2019-04-16 16:14:02,653 - INFO - Computing model performance on validation data ...
2019-04-16 16:14:02,655 - INFO - Finished decoding data: 0/500 ...
2019-04-16 16:14:02,656 - INFO - precomputing L2-norms of doc weight vectors
2019-04-16 16:29:23,758 - INFO - Reading data done!
2019-04-16 16:29:23,852 - INFO - MODEL HAS 10364933 params
2019-04-16 16:29:30,872 - INFO - Computing model performance on validation data ...
2019-04-16 16:29:30,872 - INFO - Finished decoding data: 0/500 ...
2019-04-16 16:29:57,327 - INFO - Reading data done!
2019-04-16 16:29:57,406 - INFO - MODEL HAS 10364933 params
2019-04-16 16:29:57,463 - INFO - Computing model performance on validation data ...
2019-04-16 16:29:57,464 - INFO - Finished decoding data: 0/500 ...
2019-04-16 16:30:10,807 - INFO - Reading data done!
2019-04-16 16:30:10,901 - INFO - MODEL HAS 10364933 params
2019-04-16 16:30:17,542 - INFO - Computing model performance on validation data ...
2019-04-16 16:30:17,543 - INFO - Finished decoding data: 0/500 ...
2019-04-16 16:33:31,160 - INFO - Reading data done!
2019-04-16 16:33:31,239 - INFO - MODEL HAS 10364933 params
2019-04-16 16:33:31,295 - INFO - Computing model performance on validation data ...
2019-04-16 16:33:31,296 - INFO - Finished decoding data: 0/500 ...
2019-04-16 16:33:56,355 - INFO - Reading data done!
2019-04-16 16:33:56,450 - INFO - MODEL HAS 10364933 params
2019-04-16 16:34:02,934 - INFO - Computing model performance on validation data ...
2019-04-16 16:34:02,935 - INFO - Finished decoding data: 0/500 ...
2019-04-16 16:36:47,210 - INFO - Reading data done!
2019-04-16 16:36:47,300 - INFO - MODEL HAS 10364933 params
2019-04-16 16:36:53,739 - INFO - Computing model performance on validation data ...
2019-04-16 16:36:53,740 - INFO - Finished decoding data: 0/500 ...
2019-04-16 16:37:00,274 - INFO - Finished decoding data: 100/500 ...
2019-04-16 16:37:06,765 - INFO - Finished decoding data: 200/500 ...
2019-04-16 16:37:13,235 - INFO - Finished decoding data: 300/500 ...
2019-04-16 16:37:19,703 - INFO - Finished decoding data: 400/500 ...
2019-04-16 16:37:26,206 - INFO - eval_precision: 0.016591
2019-04-16 16:37:26,207 - INFO - eval_recall: 0.017512
2019-04-16 16:37:26,207 - INFO - eval_edit_distance: 7.356000
2019-04-16 16:37:26,208 - INFO - eval_rouge: 0.145004
2019-04-16 16:39:26,163 - INFO - Reading data done!
2019-04-16 16:39:26,256 - INFO - MODEL HAS 10364933 params
2019-04-16 16:39:32,647 - INFO - Computing model performance on validation data ...
2019-04-16 16:39:32,648 - INFO - Finished decoding data: 0/500 ...
2019-04-16 16:39:39,189 - INFO - Finished decoding data: 100/500 ...
2019-04-16 16:39:45,672 - INFO - Finished decoding data: 200/500 ...
2019-04-16 16:39:52,153 - INFO - Finished decoding data: 300/500 ...
2019-04-16 16:39:58,651 - INFO - Finished decoding data: 400/500 ...
2019-04-16 16:40:05,192 - INFO - eval_precision: 0.056907
2019-04-16 16:40:05,193 - INFO - eval_recall: 0.073872
2019-04-16 16:40:05,193 - INFO - eval_edit_distance: 7.114000
2019-04-16 16:40:05,194 - INFO - eval_rouge: 0.177352
2019-04-16 16:43:33,381 - INFO - Reading data done!
2019-04-16 16:43:33,453 - INFO - MODEL HAS 10364933 params
2019-04-16 16:43:33,507 - INFO - Computing model performance on validation data ...
2019-04-16 16:43:33,508 - INFO - Finished decoding data: 0/500 ...
2019-04-16 16:43:39,981 - INFO - Finished decoding data: 100/500 ...
2019-04-16 16:43:46,561 - INFO - Finished decoding data: 200/500 ...
2019-04-16 16:43:52,995 - INFO - Finished decoding data: 300/500 ...
2019-04-16 16:43:59,403 - INFO - Finished decoding data: 400/500 ...
2019-04-16 16:44:05,884 - INFO - eval_precision: 0.075953
2019-04-16 16:44:05,885 - INFO - eval_recall: 0.181821
2019-04-16 16:44:05,885 - INFO - eval_edit_distance: 4.532000
2019-04-16 16:44:05,886 - INFO - eval_rouge: 0.317713
2019-04-16 16:59:50,726 - INFO - Reading data done!
2019-04-16 16:59:50,820 - INFO - MODEL HAS 10364933 params
2019-04-16 16:59:57,303 - INFO - Computing model performance on validation data ...
2019-04-16 16:59:57,304 - INFO - Finished decoding data: 0/500 ...
2019-04-16 17:00:03,891 - INFO - Finished decoding data: 100/500 ...
2019-04-16 17:00:10,296 - INFO - Finished decoding data: 200/500 ...
2019-04-16 17:00:16,775 - INFO - Finished decoding data: 300/500 ...
2019-04-16 17:00:26,367 - INFO - Finished decoding data: 400/500 ...
2019-04-16 17:00:32,737 - INFO - eval_precision: 0.045328
2019-04-16 17:00:32,737 - INFO - eval_recall: 0.103897
2019-04-16 17:00:32,738 - INFO - eval_edit_distance: 4.614000
2019-04-16 17:00:32,738 - INFO - eval_rouge: 0.286079
2019-04-16 19:08:04,658 - INFO - Reading data done!
2019-04-16 19:08:04,754 - INFO - MODEL HAS 10364933 params
2019-04-16 19:08:11,485 - INFO - Computing model performance on validation data ...
2019-04-16 19:08:11,486 - INFO - Finished decoding data: 0/500 ...
2019-04-16 19:08:18,957 - INFO - Finished decoding data: 100/500 ...
2019-04-16 19:08:26,327 - INFO - Finished decoding data: 200/500 ...
2019-04-16 19:08:33,642 - INFO - Finished decoding data: 300/500 ...
2019-04-16 19:08:41,035 - INFO - Finished decoding data: 400/500 ...
2019-04-16 19:08:48,348 - INFO - eval_precision: 0.075942
2019-04-16 19:08:48,349 - INFO - eval_recall: 0.165841
2019-04-16 19:08:48,349 - INFO - eval_edit_distance: 4.878000
2019-04-16 19:08:48,350 - INFO - eval_rouge: 0.273941
2019-04-26 00:09:00,151 - INFO - Reading data done!
2019-04-26 00:09:00,244 - INFO - MODEL HAS 10364933 params
2019-04-26 00:09:07,164 - INFO - Computing model performance on validation data ...
2019-04-26 00:09:07,165 - INFO - Finished decoding data: 0/500 ...
2019-04-26 00:09:14,028 - INFO - Finished decoding data: 100/500 ...
2019-04-26 00:09:20,625 - INFO - Finished decoding data: 200/500 ...
2019-04-26 00:09:27,427 - INFO - Finished decoding data: 300/500 ...
2019-04-26 00:09:34,278 - INFO - Finished decoding data: 400/500 ...
2019-04-26 00:09:41,194 - INFO - eval_precision: 0.059544
2019-04-26 00:09:41,194 - INFO - eval_recall: 0.095003
2019-04-26 00:09:41,195 - INFO - eval_edit_distance: 7.200000
2019-04-26 00:09:41,195 - INFO - eval_rouge: 0.140817
2019-04-26 00:12:12,488 - INFO - Reading data done!
2019-04-26 00:12:12,567 - INFO - MODEL HAS 10364933 params
2019-04-26 00:12:12,629 - INFO - Computing model performance on validation data ...
2019-04-26 00:25:47,847 - INFO - Reading data done!
2019-04-26 00:25:47,946 - INFO - MODEL HAS 10364933 params
2019-04-26 00:25:54,785 - INFO - Computing model performance on validation data ...
2019-04-26 00:27:45,567 - INFO - Reading data done!
2019-04-26 00:27:45,669 - INFO - MODEL HAS 10364933 params
2019-04-26 00:27:52,490 - INFO - Computing model performance on validation data ...
2019-04-26 00:27:52,491 - INFO - Finished decoding data: 0/500 ...
2019-04-26 00:27:59,370 - INFO - Finished decoding data: 100/500 ...
2019-04-26 00:28:06,245 - INFO - Finished decoding data: 200/500 ...
2019-04-26 00:28:13,126 - INFO - Finished decoding data: 300/500 ...
2019-04-26 00:28:20,010 - INFO - Finished decoding data: 400/500 ...
2019-04-26 00:28:26,986 - INFO - eval_precision: 0.056231
2019-04-26 00:28:26,987 - INFO - eval_recall: 0.064271
2019-04-26 00:28:26,988 - INFO - eval_edit_distance: 7.156000
2019-04-26 00:28:26,988 - INFO - eval_rouge: 0.139527
2019-04-26 00:31:01,077 - INFO - Reading data done!
2019-04-26 00:31:01,177 - INFO - MODEL HAS 10364933 params
2019-04-26 00:31:07,960 - INFO - Computing model performance on validation data ...
2019-04-26 00:31:07,961 - INFO - Finished decoding data: 0/500 ...
2019-04-26 00:31:14,878 - INFO - Finished decoding data: 100/500 ...
2019-04-26 00:31:21,828 - INFO - Finished decoding data: 200/500 ...
2019-04-26 00:31:28,774 - INFO - Finished decoding data: 300/500 ...
2019-04-26 00:31:35,718 - INFO - Finished decoding data: 400/500 ...
2019-04-26 00:31:42,678 - INFO - eval_precision: 0.058326
2019-04-26 00:31:42,679 - INFO - eval_recall: 0.074563
2019-04-26 00:31:42,679 - INFO - eval_edit_distance: 7.146000
2019-04-26 00:31:42,680 - INFO - eval_rouge: 0.144310
2019-04-26 00:34:12,309 - INFO - Reading data done!
2019-04-26 00:34:12,386 - INFO - MODEL HAS 10364933 params
2019-04-26 00:34:12,445 - INFO - Computing model performance on validation data ...
2019-04-26 00:34:12,446 - INFO - Finished decoding data: 0/500 ...
2019-04-26 00:34:19,437 - INFO - Finished decoding data: 100/500 ...
2019-04-26 00:34:26,408 - INFO - Finished decoding data: 200/500 ...
2019-04-26 00:34:33,338 - INFO - Finished decoding data: 300/500 ...
2019-04-26 00:34:40,288 - INFO - Finished decoding data: 400/500 ...
2019-04-26 00:36:37,942 - INFO - Reading data done!
2019-04-26 00:36:38,042 - INFO - MODEL HAS 10364933 params
2019-04-26 00:36:45,006 - INFO - Computing model performance on validation data ...
2019-04-26 00:36:45,007 - INFO - Finished decoding data: 0/500 ...
2019-04-26 00:36:51,994 - INFO - Finished decoding data: 100/500 ...
2019-04-26 00:36:58,932 - INFO - Finished decoding data: 200/500 ...
2019-04-26 00:37:05,911 - INFO - Finished decoding data: 300/500 ...
2019-04-26 00:37:12,921 - INFO - Finished decoding data: 400/500 ...
2019-04-26 00:40:06,359 - INFO - Reading data done!
2019-04-26 00:40:06,465 - INFO - MODEL HAS 10364933 params
2019-04-26 00:40:13,429 - INFO - Computing model performance on validation data ...
2019-04-26 00:40:13,430 - INFO - Finished decoding data: 0/500 ...
2019-04-26 00:40:20,399 - INFO - Finished decoding data: 100/500 ...
2019-04-26 00:40:27,352 - INFO - Finished decoding data: 200/500 ...
2019-04-26 00:40:34,270 - INFO - Finished decoding data: 300/500 ...
2019-04-26 00:40:41,218 - INFO - Finished decoding data: 400/500 ...
2019-04-26 00:42:12,918 - INFO - Reading data done!
2019-04-26 00:42:13,017 - INFO - MODEL HAS 10364933 params
2019-04-26 00:42:19,837 - INFO - Computing model performance on validation data ...
2019-04-26 00:42:19,838 - INFO - Finished decoding data: 0/500 ...
2019-04-26 00:42:26,822 - INFO - Finished decoding data: 100/500 ...
2019-04-26 00:42:33,727 - INFO - Finished decoding data: 200/500 ...
2019-04-26 00:42:40,635 - INFO - Finished decoding data: 300/500 ...
2019-04-26 00:42:47,594 - INFO - Finished decoding data: 400/500 ...
2019-04-26 00:42:54,550 - INFO - eval_precision: 0.052130
2019-04-26 00:42:54,551 - INFO - eval_recall: 0.078866
2019-04-26 00:42:54,551 - INFO - eval_edit_distance: 7.162000
2019-04-26 00:42:54,551 - INFO - eval_rouge: 0.142978
2019-04-26 00:57:58,692 - INFO - Reading data done!
2019-04-26 00:57:58,790 - INFO - MODEL HAS 10364933 params
2019-04-26 00:58:05,537 - INFO - Computing model performance on validation data ...
2019-04-26 00:58:05,538 - INFO - Finished decoding data: 0/500 ...
2019-04-26 00:58:12,468 - INFO - Finished decoding data: 100/500 ...
2019-04-26 00:58:19,350 - INFO - Finished decoding data: 200/500 ...
2019-04-26 00:58:26,144 - INFO - Finished decoding data: 300/500 ...
2019-04-26 00:58:32,720 - INFO - Finished decoding data: 400/500 ...
2019-04-26 00:58:39,342 - INFO - eval_precision: 0.069222
2019-04-26 00:58:39,343 - INFO - eval_recall: 0.090647
2019-04-26 00:58:39,343 - INFO - eval_edit_distance: 7.142000
2019-04-26 00:58:39,344 - INFO - eval_bleu: 9.447268
