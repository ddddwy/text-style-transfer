2019-03-28 23:58:28,845 - INFO - collecting all words and their counts
2019-03-28 23:58:28,846 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-03-28 23:58:28,848 - INFO - collected 1081 word types and 500 unique tags from a corpus of 500 examples and 3974 words
2019-03-28 23:58:28,849 - INFO - Loading a fresh vocabulary
2019-03-28 23:58:28,850 - INFO - effective_min_count=5 retains 123 unique words (11% of original 1081, drops 958)
2019-03-28 23:58:28,850 - INFO - effective_min_count=5 leaves 2576 word corpus (64% of original 3974, drops 1398)
2019-03-28 23:58:28,851 - INFO - deleting the raw counts dictionary of 1081 items
2019-03-28 23:58:28,852 - INFO - sample=0.001 downsamples 91 most-common words
2019-03-28 23:58:28,853 - INFO - downsampling leaves estimated 1072 word corpus (41.6% of prior 2576)
2019-03-28 23:58:28,853 - INFO - estimated required memory for 123 words and 100 dimensions: 459900 bytes
2019-03-28 23:58:28,854 - INFO - resetting layer weights
2019-03-28 23:58:28,864 - INFO - training model with 3 workers on 123 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-03-28 23:58:28,869 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-28 23:58:28,870 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-28 23:58:28,878 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-28 23:58:28,879 - INFO - EPOCH - 1 : training on 3974 raw words (1555 effective words) took 0.0s, 152449 effective words/s
2019-03-28 23:58:28,881 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-28 23:58:28,882 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-28 23:58:28,891 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-28 23:58:28,891 - INFO - EPOCH - 2 : training on 3974 raw words (1574 effective words) took 0.0s, 152894 effective words/s
2019-03-28 23:58:28,894 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-28 23:58:28,895 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-28 23:58:28,905 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-28 23:58:28,905 - INFO - EPOCH - 3 : training on 3974 raw words (1559 effective words) took 0.0s, 133696 effective words/s
2019-03-28 23:58:28,908 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-28 23:58:28,909 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-28 23:58:28,918 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-28 23:58:28,918 - INFO - EPOCH - 4 : training on 3974 raw words (1593 effective words) took 0.0s, 152103 effective words/s
2019-03-28 23:58:28,921 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-28 23:58:28,921 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-28 23:58:28,931 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-28 23:58:28,931 - INFO - EPOCH - 5 : training on 3974 raw words (1591 effective words) took 0.0s, 150089 effective words/s
2019-03-28 23:58:28,932 - INFO - training on a 19870 raw words (7872 effective words) took 0.1s, 118014 effective words/s
2019-03-28 23:58:28,932 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-03-28 23:58:28,937 - INFO - Reading data done!
2019-03-28 23:58:29,119 - INFO - MODEL HAS 10364933 params
2019-03-28 23:58:35,120 - INFO - Computing model performance on validation data ...
2019-03-28 23:58:35,121 - INFO - Finished decoding data: 0/500 ...
2019-03-28 23:58:35,123 - INFO - precomputing L2-norms of doc weight vectors
2019-03-28 23:58:57,676 - INFO - Finished decoding data: 100/500 ...
2019-03-28 23:59:19,482 - INFO - Finished decoding data: 200/500 ...
2019-03-28 23:59:38,991 - INFO - Finished decoding data: 300/500 ...
2019-03-28 23:59:59,669 - INFO - Finished decoding data: 400/500 ...
2019-03-29 00:00:20,863 - INFO - eval_precision: 0.014309
2019-03-29 00:00:20,865 - INFO - eval_recall: 0.035964
2019-03-29 00:00:20,866 - INFO - eval_edit_distance: 5.698000
2019-03-29 00:00:20,866 - INFO - eval_rouge: 0.222648
2019-03-29 00:08:59,786 - INFO - collecting all words and their counts
2019-03-29 00:08:59,788 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-03-29 00:08:59,790 - INFO - collected 1081 word types and 500 unique tags from a corpus of 500 examples and 3974 words
2019-03-29 00:08:59,791 - INFO - Loading a fresh vocabulary
2019-03-29 00:08:59,792 - INFO - effective_min_count=5 retains 123 unique words (11% of original 1081, drops 958)
2019-03-29 00:08:59,793 - INFO - effective_min_count=5 leaves 2576 word corpus (64% of original 3974, drops 1398)
2019-03-29 00:08:59,794 - INFO - deleting the raw counts dictionary of 1081 items
2019-03-29 00:08:59,795 - INFO - sample=0.001 downsamples 91 most-common words
2019-03-29 00:08:59,795 - INFO - downsampling leaves estimated 1072 word corpus (41.6% of prior 2576)
2019-03-29 00:08:59,796 - INFO - estimated required memory for 123 words and 100 dimensions: 459900 bytes
2019-03-29 00:08:59,797 - INFO - resetting layer weights
2019-03-29 00:08:59,809 - INFO - training model with 3 workers on 123 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-03-29 00:08:59,812 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:08:59,813 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:08:59,821 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:08:59,822 - INFO - EPOCH - 1 : training on 3974 raw words (1555 effective words) took 0.0s, 157157 effective words/s
2019-03-29 00:08:59,824 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:08:59,825 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:08:59,834 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:08:59,835 - INFO - EPOCH - 2 : training on 3974 raw words (1574 effective words) took 0.0s, 144938 effective words/s
2019-03-29 00:08:59,837 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:08:59,838 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:08:59,847 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:08:59,847 - INFO - EPOCH - 3 : training on 3974 raw words (1559 effective words) took 0.0s, 155557 effective words/s
2019-03-29 00:08:59,850 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:08:59,850 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:08:59,859 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:08:59,859 - INFO - EPOCH - 4 : training on 3974 raw words (1593 effective words) took 0.0s, 161129 effective words/s
2019-03-29 00:08:59,861 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:08:59,863 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:08:59,871 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:08:59,872 - INFO - EPOCH - 5 : training on 3974 raw words (1591 effective words) took 0.0s, 154373 effective words/s
2019-03-29 00:08:59,872 - INFO - training on a 19870 raw words (7872 effective words) took 0.1s, 125916 effective words/s
2019-03-29 00:08:59,873 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-03-29 00:08:59,878 - INFO - Reading data done!
2019-03-29 00:09:00,059 - INFO - MODEL HAS 10364933 params
2019-03-29 00:09:05,792 - INFO - Computing model performance on validation data ...
2019-03-29 00:09:05,792 - INFO - Finished decoding data: 0/500 ...
2019-03-29 00:09:05,794 - INFO - precomputing L2-norms of doc weight vectors
2019-03-29 00:09:29,329 - INFO - Finished decoding data: 100/500 ...
2019-03-29 00:09:51,724 - INFO - Finished decoding data: 200/500 ...
2019-03-29 00:10:13,646 - INFO - Finished decoding data: 300/500 ...
2019-03-29 00:10:33,941 - INFO - Finished decoding data: 400/500 ...
2019-03-29 00:10:56,176 - INFO - eval_precision: 0.013983
2019-03-29 00:10:56,177 - INFO - eval_recall: 0.039961
2019-03-29 00:10:56,178 - INFO - eval_edit_distance: 5.550000
2019-03-29 00:10:56,178 - INFO - eval_rouge: 0.241387
2019-03-29 00:12:30,227 - INFO - collecting all words and their counts
2019-03-29 00:12:30,228 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-03-29 00:12:30,231 - INFO - collected 1081 word types and 500 unique tags from a corpus of 500 examples and 3974 words
2019-03-29 00:12:30,231 - INFO - Loading a fresh vocabulary
2019-03-29 00:12:30,232 - INFO - effective_min_count=5 retains 123 unique words (11% of original 1081, drops 958)
2019-03-29 00:12:30,233 - INFO - effective_min_count=5 leaves 2576 word corpus (64% of original 3974, drops 1398)
2019-03-29 00:12:30,234 - INFO - deleting the raw counts dictionary of 1081 items
2019-03-29 00:12:30,235 - INFO - sample=0.001 downsamples 91 most-common words
2019-03-29 00:12:30,235 - INFO - downsampling leaves estimated 1072 word corpus (41.6% of prior 2576)
2019-03-29 00:12:30,236 - INFO - estimated required memory for 123 words and 100 dimensions: 459900 bytes
2019-03-29 00:12:30,237 - INFO - resetting layer weights
2019-03-29 00:12:30,248 - INFO - training model with 3 workers on 123 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-03-29 00:12:30,252 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:12:30,253 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:12:30,262 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:12:30,262 - INFO - EPOCH - 1 : training on 3974 raw words (1555 effective words) took 0.0s, 149495 effective words/s
2019-03-29 00:12:30,265 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:12:30,266 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:12:30,274 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:12:30,275 - INFO - EPOCH - 2 : training on 3974 raw words (1574 effective words) took 0.0s, 161839 effective words/s
2019-03-29 00:12:30,277 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:12:30,278 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:12:30,286 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:12:30,287 - INFO - EPOCH - 3 : training on 3974 raw words (1559 effective words) took 0.0s, 156423 effective words/s
2019-03-29 00:12:30,289 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:12:30,290 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:12:30,299 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:12:30,299 - INFO - EPOCH - 4 : training on 3974 raw words (1593 effective words) took 0.0s, 161797 effective words/s
2019-03-29 00:12:30,302 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:12:30,302 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:12:30,311 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:12:30,311 - INFO - EPOCH - 5 : training on 3974 raw words (1591 effective words) took 0.0s, 162134 effective words/s
2019-03-29 00:12:30,312 - INFO - training on a 19870 raw words (7872 effective words) took 0.1s, 126738 effective words/s
2019-03-29 00:12:30,312 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-03-29 00:12:30,317 - INFO - Reading data done!
2019-03-29 00:12:30,497 - INFO - MODEL HAS 10364933 params
2019-03-29 00:12:36,255 - INFO - Computing model performance on validation data ...
2019-03-29 00:12:36,256 - INFO - Finished decoding data: 0/500 ...
2019-03-29 00:12:36,304 - INFO - precomputing L2-norms of doc weight vectors
2019-03-29 00:12:59,598 - INFO - Finished decoding data: 100/500 ...
2019-03-29 00:13:21,763 - INFO - Finished decoding data: 200/500 ...
2019-03-29 00:13:39,703 - INFO - Finished decoding data: 300/500 ...
2019-03-29 00:14:02,815 - INFO - Finished decoding data: 400/500 ...
2019-03-29 00:14:21,012 - INFO - eval_precision: 0.019177
2019-03-29 00:14:21,013 - INFO - eval_recall: 0.047952
2019-03-29 00:14:21,013 - INFO - eval_edit_distance: 5.672000
2019-03-29 00:14:21,014 - INFO - eval_rouge: 0.229902
2019-03-29 00:16:53,262 - INFO - collecting all words and their counts
2019-03-29 00:16:53,263 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-03-29 00:16:53,265 - INFO - collected 1081 word types and 500 unique tags from a corpus of 500 examples and 3974 words
2019-03-29 00:16:53,266 - INFO - Loading a fresh vocabulary
2019-03-29 00:16:53,267 - INFO - effective_min_count=5 retains 123 unique words (11% of original 1081, drops 958)
2019-03-29 00:16:53,267 - INFO - effective_min_count=5 leaves 2576 word corpus (64% of original 3974, drops 1398)
2019-03-29 00:16:53,268 - INFO - deleting the raw counts dictionary of 1081 items
2019-03-29 00:16:53,270 - INFO - sample=0.001 downsamples 91 most-common words
2019-03-29 00:16:53,270 - INFO - downsampling leaves estimated 1072 word corpus (41.6% of prior 2576)
2019-03-29 00:16:53,271 - INFO - estimated required memory for 123 words and 100 dimensions: 459900 bytes
2019-03-29 00:16:53,271 - INFO - resetting layer weights
2019-03-29 00:16:53,283 - INFO - training model with 3 workers on 123 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-03-29 00:16:53,287 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:16:53,288 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:16:53,296 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:16:53,296 - INFO - EPOCH - 1 : training on 3974 raw words (1555 effective words) took 0.0s, 158849 effective words/s
2019-03-29 00:16:53,300 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:16:53,301 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:16:53,309 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:16:53,309 - INFO - EPOCH - 2 : training on 3974 raw words (1574 effective words) took 0.0s, 164149 effective words/s
2019-03-29 00:16:53,312 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:16:53,313 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:16:53,321 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:16:53,321 - INFO - EPOCH - 3 : training on 3974 raw words (1559 effective words) took 0.0s, 163934 effective words/s
2019-03-29 00:16:53,323 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:16:53,324 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:16:53,333 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:16:53,333 - INFO - EPOCH - 4 : training on 3974 raw words (1593 effective words) took 0.0s, 162241 effective words/s
2019-03-29 00:16:53,335 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:16:53,336 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:16:53,344 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:16:53,345 - INFO - EPOCH - 5 : training on 3974 raw words (1591 effective words) took 0.0s, 168447 effective words/s
2019-03-29 00:16:53,345 - INFO - training on a 19870 raw words (7872 effective words) took 0.1s, 129351 effective words/s
2019-03-29 00:16:53,346 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-03-29 00:16:53,351 - INFO - Reading data done!
2019-03-29 00:16:53,532 - INFO - MODEL HAS 10364933 params
2019-03-29 00:16:59,226 - INFO - Computing model performance on validation data ...
2019-03-29 00:16:59,227 - INFO - Finished decoding data: 0/500 ...
2019-03-29 00:16:59,230 - INFO - precomputing L2-norms of doc weight vectors
2019-03-29 00:37:07,257 - INFO - collecting all words and their counts
2019-03-29 00:37:07,258 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-03-29 00:37:07,260 - INFO - collected 1081 word types and 500 unique tags from a corpus of 500 examples and 3974 words
2019-03-29 00:37:07,261 - INFO - Loading a fresh vocabulary
2019-03-29 00:37:07,262 - INFO - effective_min_count=5 retains 123 unique words (11% of original 1081, drops 958)
2019-03-29 00:37:07,262 - INFO - effective_min_count=5 leaves 2576 word corpus (64% of original 3974, drops 1398)
2019-03-29 00:37:07,263 - INFO - deleting the raw counts dictionary of 1081 items
2019-03-29 00:37:07,265 - INFO - sample=0.001 downsamples 91 most-common words
2019-03-29 00:37:07,265 - INFO - downsampling leaves estimated 1072 word corpus (41.6% of prior 2576)
2019-03-29 00:37:07,266 - INFO - estimated required memory for 123 words and 100 dimensions: 459900 bytes
2019-03-29 00:37:07,266 - INFO - resetting layer weights
2019-03-29 00:37:07,277 - INFO - training model with 3 workers on 123 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-03-29 00:37:07,282 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:37:07,283 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:37:07,291 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:37:07,292 - INFO - EPOCH - 1 : training on 3974 raw words (1555 effective words) took 0.0s, 155592 effective words/s
2019-03-29 00:37:07,294 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:37:07,295 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:37:07,304 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:37:07,304 - INFO - EPOCH - 2 : training on 3974 raw words (1574 effective words) took 0.0s, 157161 effective words/s
2019-03-29 00:37:07,307 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:37:07,307 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:37:07,316 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:37:07,317 - INFO - EPOCH - 3 : training on 3974 raw words (1559 effective words) took 0.0s, 157510 effective words/s
2019-03-29 00:37:07,319 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:37:07,320 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:37:07,328 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:37:07,329 - INFO - EPOCH - 4 : training on 3974 raw words (1593 effective words) took 0.0s, 161120 effective words/s
2019-03-29 00:37:07,331 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:37:07,332 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:37:07,341 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:37:07,341 - INFO - EPOCH - 5 : training on 3974 raw words (1591 effective words) took 0.0s, 149960 effective words/s
2019-03-29 00:37:07,342 - INFO - training on a 19870 raw words (7872 effective words) took 0.1s, 122000 effective words/s
2019-03-29 00:37:07,342 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-03-29 00:37:07,347 - INFO - Reading data done!
2019-03-29 00:37:07,527 - INFO - MODEL HAS 10364933 params
2019-03-29 00:37:13,311 - INFO - Computing model performance on validation data ...
2019-03-29 00:37:13,312 - INFO - Finished decoding data: 0/500 ...
2019-03-29 00:37:45,959 - INFO - collecting all words and their counts
2019-03-29 00:37:45,960 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-03-29 00:37:45,962 - INFO - collected 1081 word types and 500 unique tags from a corpus of 500 examples and 3974 words
2019-03-29 00:37:45,963 - INFO - Loading a fresh vocabulary
2019-03-29 00:37:45,964 - INFO - effective_min_count=5 retains 123 unique words (11% of original 1081, drops 958)
2019-03-29 00:37:45,964 - INFO - effective_min_count=5 leaves 2576 word corpus (64% of original 3974, drops 1398)
2019-03-29 00:37:45,965 - INFO - deleting the raw counts dictionary of 1081 items
2019-03-29 00:37:45,966 - INFO - sample=0.001 downsamples 91 most-common words
2019-03-29 00:37:45,967 - INFO - downsampling leaves estimated 1072 word corpus (41.6% of prior 2576)
2019-03-29 00:37:45,968 - INFO - estimated required memory for 123 words and 100 dimensions: 459900 bytes
2019-03-29 00:37:45,968 - INFO - resetting layer weights
2019-03-29 00:37:45,980 - INFO - training model with 3 workers on 123 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-03-29 00:37:45,983 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:37:45,984 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:37:45,992 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:37:45,993 - INFO - EPOCH - 1 : training on 3974 raw words (1555 effective words) took 0.0s, 152727 effective words/s
2019-03-29 00:37:45,995 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:37:45,996 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:37:46,005 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:37:46,005 - INFO - EPOCH - 2 : training on 3974 raw words (1574 effective words) took 0.0s, 152322 effective words/s
2019-03-29 00:37:46,008 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:37:46,009 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:37:46,017 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:37:46,017 - INFO - EPOCH - 3 : training on 3974 raw words (1559 effective words) took 0.0s, 157638 effective words/s
2019-03-29 00:37:46,020 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:37:46,021 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:37:46,030 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:37:46,030 - INFO - EPOCH - 4 : training on 3974 raw words (1593 effective words) took 0.0s, 153009 effective words/s
2019-03-29 00:37:46,033 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:37:46,033 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:37:46,042 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:37:46,043 - INFO - EPOCH - 5 : training on 3974 raw words (1591 effective words) took 0.0s, 154929 effective words/s
2019-03-29 00:37:46,043 - INFO - training on a 19870 raw words (7872 effective words) took 0.1s, 124920 effective words/s
2019-03-29 00:37:46,044 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-03-29 00:37:46,049 - INFO - Reading data done!
2019-03-29 00:37:46,231 - INFO - MODEL HAS 10364933 params
2019-03-29 00:37:52,032 - INFO - Computing model performance on validation data ...
2019-03-29 00:37:52,033 - INFO - Finished decoding data: 0/500 ...
2019-03-29 00:37:52,036 - INFO - precomputing L2-norms of doc weight vectors
2019-03-29 00:38:14,921 - INFO - Finished decoding data: 100/500 ...
2019-03-29 00:41:26,500 - INFO - collecting all words and their counts
2019-03-29 00:41:26,501 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-03-29 00:41:26,503 - INFO - collected 1081 word types and 500 unique tags from a corpus of 500 examples and 3974 words
2019-03-29 00:41:26,504 - INFO - Loading a fresh vocabulary
2019-03-29 00:41:26,504 - INFO - effective_min_count=5 retains 123 unique words (11% of original 1081, drops 958)
2019-03-29 00:41:26,505 - INFO - effective_min_count=5 leaves 2576 word corpus (64% of original 3974, drops 1398)
2019-03-29 00:41:26,506 - INFO - deleting the raw counts dictionary of 1081 items
2019-03-29 00:41:26,507 - INFO - sample=0.001 downsamples 91 most-common words
2019-03-29 00:41:26,507 - INFO - downsampling leaves estimated 1072 word corpus (41.6% of prior 2576)
2019-03-29 00:41:26,508 - INFO - estimated required memory for 123 words and 100 dimensions: 459900 bytes
2019-03-29 00:41:26,509 - INFO - resetting layer weights
2019-03-29 00:41:26,519 - INFO - training model with 3 workers on 123 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-03-29 00:41:26,523 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:41:26,524 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:41:26,532 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:41:26,533 - INFO - EPOCH - 1 : training on 3974 raw words (1555 effective words) took 0.0s, 159859 effective words/s
2019-03-29 00:41:26,535 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:41:26,536 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:41:26,544 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:41:26,545 - INFO - EPOCH - 2 : training on 3974 raw words (1574 effective words) took 0.0s, 159914 effective words/s
2019-03-29 00:41:26,547 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:41:26,548 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:41:26,556 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:41:26,557 - INFO - EPOCH - 3 : training on 3974 raw words (1559 effective words) took 0.0s, 163948 effective words/s
2019-03-29 00:41:26,559 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:41:26,560 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:41:26,568 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:41:26,568 - INFO - EPOCH - 4 : training on 3974 raw words (1593 effective words) took 0.0s, 174595 effective words/s
2019-03-29 00:41:26,570 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:41:26,571 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:41:26,580 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:41:26,580 - INFO - EPOCH - 5 : training on 3974 raw words (1591 effective words) took 0.0s, 155903 effective words/s
2019-03-29 00:41:26,581 - INFO - training on a 19870 raw words (7872 effective words) took 0.1s, 127318 effective words/s
2019-03-29 00:41:26,581 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-03-29 00:41:26,586 - INFO - Reading data done!
2019-03-29 00:41:26,771 - INFO - MODEL HAS 10364933 params
2019-03-29 00:41:32,555 - INFO - Computing model performance on validation data ...
2019-03-29 00:41:32,555 - INFO - Finished decoding data: 0/500 ...
2019-03-29 00:41:32,557 - INFO - precomputing L2-norms of doc weight vectors
2019-03-29 00:41:56,081 - INFO - Finished decoding data: 100/500 ...
2019-03-29 00:46:29,136 - INFO - collecting all words and their counts
2019-03-29 00:46:29,137 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-03-29 00:46:29,139 - INFO - collected 1081 word types and 500 unique tags from a corpus of 500 examples and 3974 words
2019-03-29 00:46:29,139 - INFO - Loading a fresh vocabulary
2019-03-29 00:46:29,140 - INFO - effective_min_count=5 retains 123 unique words (11% of original 1081, drops 958)
2019-03-29 00:46:29,141 - INFO - effective_min_count=5 leaves 2576 word corpus (64% of original 3974, drops 1398)
2019-03-29 00:46:29,142 - INFO - deleting the raw counts dictionary of 1081 items
2019-03-29 00:46:29,143 - INFO - sample=0.001 downsamples 91 most-common words
2019-03-29 00:46:29,143 - INFO - downsampling leaves estimated 1072 word corpus (41.6% of prior 2576)
2019-03-29 00:46:29,144 - INFO - estimated required memory for 123 words and 100 dimensions: 459900 bytes
2019-03-29 00:46:29,145 - INFO - resetting layer weights
2019-03-29 00:46:29,155 - INFO - training model with 3 workers on 123 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-03-29 00:46:29,160 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:46:29,160 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:46:29,169 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:46:29,170 - INFO - EPOCH - 1 : training on 3974 raw words (1555 effective words) took 0.0s, 154456 effective words/s
2019-03-29 00:46:29,172 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:46:29,173 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:46:29,181 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:46:29,182 - INFO - EPOCH - 2 : training on 3974 raw words (1574 effective words) took 0.0s, 157025 effective words/s
2019-03-29 00:46:29,184 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:46:29,185 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:46:29,194 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:46:29,194 - INFO - EPOCH - 3 : training on 3974 raw words (1559 effective words) took 0.0s, 153817 effective words/s
2019-03-29 00:46:29,197 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:46:29,198 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:46:29,206 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:46:29,207 - INFO - EPOCH - 4 : training on 3974 raw words (1593 effective words) took 0.0s, 161255 effective words/s
2019-03-29 00:46:29,209 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:46:29,210 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:46:29,219 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:46:29,219 - INFO - EPOCH - 5 : training on 3974 raw words (1591 effective words) took 0.0s, 155374 effective words/s
2019-03-29 00:46:29,221 - INFO - training on a 19870 raw words (7872 effective words) took 0.1s, 119788 effective words/s
2019-03-29 00:46:29,221 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-03-29 00:46:29,226 - INFO - Reading data done!
2019-03-29 00:46:29,408 - INFO - MODEL HAS 10364933 params
2019-03-29 00:46:35,233 - INFO - Computing model performance on validation data ...
2019-03-29 00:46:35,234 - INFO - Finished decoding data: 0/500 ...
2019-03-29 00:46:35,238 - INFO - precomputing L2-norms of doc weight vectors
2019-03-29 00:47:57,648 - INFO - collecting all words and their counts
2019-03-29 00:47:57,649 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-03-29 00:47:57,651 - INFO - collected 1081 word types and 500 unique tags from a corpus of 500 examples and 3974 words
2019-03-29 00:47:57,652 - INFO - Loading a fresh vocabulary
2019-03-29 00:47:57,653 - INFO - effective_min_count=5 retains 123 unique words (11% of original 1081, drops 958)
2019-03-29 00:47:57,654 - INFO - effective_min_count=5 leaves 2576 word corpus (64% of original 3974, drops 1398)
2019-03-29 00:47:57,654 - INFO - deleting the raw counts dictionary of 1081 items
2019-03-29 00:47:57,656 - INFO - sample=0.001 downsamples 91 most-common words
2019-03-29 00:47:57,656 - INFO - downsampling leaves estimated 1072 word corpus (41.6% of prior 2576)
2019-03-29 00:47:57,657 - INFO - estimated required memory for 123 words and 100 dimensions: 459900 bytes
2019-03-29 00:47:57,658 - INFO - resetting layer weights
2019-03-29 00:47:57,668 - INFO - training model with 3 workers on 123 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-03-29 00:47:57,672 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:47:57,673 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:47:57,681 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:47:57,682 - INFO - EPOCH - 1 : training on 3974 raw words (1555 effective words) took 0.0s, 157828 effective words/s
2019-03-29 00:47:57,684 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:47:57,685 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:47:57,693 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:47:57,694 - INFO - EPOCH - 2 : training on 3974 raw words (1574 effective words) took 0.0s, 161342 effective words/s
2019-03-29 00:47:57,696 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:47:57,697 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:47:57,705 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:47:57,705 - INFO - EPOCH - 3 : training on 3974 raw words (1559 effective words) took 0.0s, 165420 effective words/s
2019-03-29 00:47:57,708 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:47:57,708 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:47:57,717 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:47:57,717 - INFO - EPOCH - 4 : training on 3974 raw words (1593 effective words) took 0.0s, 162139 effective words/s
2019-03-29 00:47:57,720 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:47:57,720 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:47:57,728 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:47:57,729 - INFO - EPOCH - 5 : training on 3974 raw words (1591 effective words) took 0.0s, 171082 effective words/s
2019-03-29 00:47:57,729 - INFO - training on a 19870 raw words (7872 effective words) took 0.1s, 128767 effective words/s
2019-03-29 00:47:57,730 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-03-29 00:47:57,735 - INFO - Reading data done!
2019-03-29 00:47:57,915 - INFO - MODEL HAS 10364933 params
2019-03-29 00:48:03,626 - INFO - Computing model performance on validation data ...
2019-03-29 00:48:03,626 - INFO - Finished decoding data: 0/500 ...
2019-03-29 00:48:03,630 - INFO - precomputing L2-norms of doc weight vectors
2019-03-29 00:48:27,165 - INFO - Finished decoding data: 100/500 ...
2019-03-29 00:51:46,529 - INFO - collecting all words and their counts
2019-03-29 00:51:46,530 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-03-29 00:51:46,532 - INFO - collected 1081 word types and 500 unique tags from a corpus of 500 examples and 3974 words
2019-03-29 00:51:46,534 - INFO - Loading a fresh vocabulary
2019-03-29 00:51:46,535 - INFO - effective_min_count=5 retains 123 unique words (11% of original 1081, drops 958)
2019-03-29 00:51:46,536 - INFO - effective_min_count=5 leaves 2576 word corpus (64% of original 3974, drops 1398)
2019-03-29 00:51:46,537 - INFO - deleting the raw counts dictionary of 1081 items
2019-03-29 00:51:46,538 - INFO - sample=0.001 downsamples 91 most-common words
2019-03-29 00:51:46,538 - INFO - downsampling leaves estimated 1072 word corpus (41.6% of prior 2576)
2019-03-29 00:51:46,539 - INFO - estimated required memory for 123 words and 100 dimensions: 459900 bytes
2019-03-29 00:51:46,540 - INFO - resetting layer weights
2019-03-29 00:51:46,550 - INFO - training model with 3 workers on 123 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-03-29 00:51:46,554 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:51:46,555 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:51:46,565 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:51:46,565 - INFO - EPOCH - 1 : training on 3974 raw words (1555 effective words) took 0.0s, 139514 effective words/s
2019-03-29 00:51:46,568 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:51:46,569 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:51:46,577 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:51:46,578 - INFO - EPOCH - 2 : training on 3974 raw words (1574 effective words) took 0.0s, 151872 effective words/s
2019-03-29 00:51:46,580 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:51:46,581 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:51:46,590 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:51:46,590 - INFO - EPOCH - 3 : training on 3974 raw words (1559 effective words) took 0.0s, 153057 effective words/s
2019-03-29 00:51:46,593 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:51:46,593 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:51:46,602 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:51:46,602 - INFO - EPOCH - 4 : training on 3974 raw words (1593 effective words) took 0.0s, 159160 effective words/s
2019-03-29 00:51:46,605 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:51:46,606 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:51:46,614 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:51:46,614 - INFO - EPOCH - 5 : training on 3974 raw words (1591 effective words) took 0.0s, 160384 effective words/s
2019-03-29 00:51:46,615 - INFO - training on a 19870 raw words (7872 effective words) took 0.1s, 123976 effective words/s
2019-03-29 00:51:46,615 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-03-29 00:51:46,620 - INFO - Reading data done!
2019-03-29 00:51:46,803 - INFO - MODEL HAS 10364933 params
2019-03-29 00:51:52,610 - INFO - Computing model performance on validation data ...
2019-03-29 00:51:52,611 - INFO - Finished decoding data: 0/500 ...
2019-03-29 00:51:52,615 - INFO - precomputing L2-norms of doc weight vectors
2019-03-29 00:52:16,310 - INFO - Finished decoding data: 100/500 ...
2019-03-29 00:52:39,913 - INFO - Finished decoding data: 200/500 ...
2019-03-29 00:53:10,403 - INFO - collecting all words and their counts
2019-03-29 00:53:10,404 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-03-29 00:53:10,406 - INFO - collected 1081 word types and 500 unique tags from a corpus of 500 examples and 3974 words
2019-03-29 00:53:10,406 - INFO - Loading a fresh vocabulary
2019-03-29 00:53:10,407 - INFO - effective_min_count=5 retains 123 unique words (11% of original 1081, drops 958)
2019-03-29 00:53:10,408 - INFO - effective_min_count=5 leaves 2576 word corpus (64% of original 3974, drops 1398)
2019-03-29 00:53:10,409 - INFO - deleting the raw counts dictionary of 1081 items
2019-03-29 00:53:10,410 - INFO - sample=0.001 downsamples 91 most-common words
2019-03-29 00:53:10,410 - INFO - downsampling leaves estimated 1072 word corpus (41.6% of prior 2576)
2019-03-29 00:53:10,411 - INFO - estimated required memory for 123 words and 100 dimensions: 459900 bytes
2019-03-29 00:53:10,412 - INFO - resetting layer weights
2019-03-29 00:53:10,423 - INFO - training model with 3 workers on 123 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-03-29 00:53:10,427 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:53:10,428 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:53:10,437 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:53:10,437 - INFO - EPOCH - 1 : training on 3974 raw words (1555 effective words) took 0.0s, 154646 effective words/s
2019-03-29 00:53:10,440 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:53:10,440 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:53:10,449 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:53:10,449 - INFO - EPOCH - 2 : training on 3974 raw words (1574 effective words) took 0.0s, 161858 effective words/s
2019-03-29 00:53:10,451 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:53:10,452 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:53:10,461 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:53:10,461 - INFO - EPOCH - 3 : training on 3974 raw words (1559 effective words) took 0.0s, 155999 effective words/s
2019-03-29 00:53:10,463 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:53:10,464 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:53:10,473 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:53:10,473 - INFO - EPOCH - 4 : training on 3974 raw words (1593 effective words) took 0.0s, 154927 effective words/s
2019-03-29 00:53:10,476 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 00:53:10,477 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 00:53:10,485 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 00:53:10,486 - INFO - EPOCH - 5 : training on 3974 raw words (1591 effective words) took 0.0s, 157232 effective words/s
2019-03-29 00:53:10,486 - INFO - training on a 19870 raw words (7872 effective words) took 0.1s, 125558 effective words/s
2019-03-29 00:53:10,487 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-03-29 00:53:10,492 - INFO - Reading data done!
2019-03-29 00:53:10,672 - INFO - MODEL HAS 10364933 params
2019-03-29 00:53:16,472 - INFO - Computing model performance on validation data ...
2019-03-29 00:53:16,472 - INFO - Finished decoding data: 0/500 ...
2019-03-29 00:53:16,475 - INFO - precomputing L2-norms of doc weight vectors
2019-03-29 00:53:39,022 - INFO - Finished decoding data: 100/500 ...
2019-03-29 00:54:00,900 - INFO - Finished decoding data: 200/500 ...
2019-03-29 00:54:25,101 - INFO - Finished decoding data: 300/500 ...
2019-03-29 00:54:48,659 - INFO - Finished decoding data: 400/500 ...
2019-03-29 00:55:11,175 - INFO - eval_precision: 0.013370
2019-03-29 00:55:11,176 - INFO - eval_recall: 0.041958
2019-03-29 00:55:11,177 - INFO - eval_edit_distance: 5.662000
2019-03-29 00:55:11,177 - INFO - eval_rouge: 0.234478
2019-03-29 01:23:46,367 - INFO - collecting all words and their counts
2019-03-29 01:23:46,368 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-03-29 01:23:46,370 - INFO - collected 1036 word types and 500 unique tags from a corpus of 500 examples and 4050 words
2019-03-29 01:23:46,371 - INFO - Loading a fresh vocabulary
2019-03-29 01:23:46,373 - INFO - effective_min_count=5 retains 121 unique words (11% of original 1036, drops 915)
2019-03-29 01:23:46,373 - INFO - effective_min_count=5 leaves 2727 word corpus (67% of original 4050, drops 1323)
2019-03-29 01:23:46,375 - INFO - deleting the raw counts dictionary of 1036 items
2019-03-29 01:23:46,376 - INFO - sample=0.001 downsamples 75 most-common words
2019-03-29 01:23:46,377 - INFO - downsampling leaves estimated 1100 word corpus (40.3% of prior 2727)
2019-03-29 01:23:46,378 - INFO - estimated required memory for 121 words and 100 dimensions: 457300 bytes
2019-03-29 01:23:46,379 - INFO - resetting layer weights
2019-03-29 01:23:46,390 - INFO - training model with 3 workers on 121 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-03-29 01:23:46,398 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 01:23:46,399 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 01:23:46,408 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 01:23:46,409 - INFO - EPOCH - 1 : training on 4050 raw words (1581 effective words) took 0.0s, 138175 effective words/s
2019-03-29 01:23:46,412 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 01:23:46,414 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 01:23:46,423 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 01:23:46,424 - INFO - EPOCH - 2 : training on 4050 raw words (1626 effective words) took 0.0s, 139648 effective words/s
2019-03-29 01:23:46,427 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 01:23:46,428 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 01:23:46,437 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 01:23:46,438 - INFO - EPOCH - 3 : training on 4050 raw words (1574 effective words) took 0.0s, 141198 effective words/s
2019-03-29 01:23:46,441 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 01:23:46,442 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 01:23:46,451 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 01:23:46,452 - INFO - EPOCH - 4 : training on 4050 raw words (1567 effective words) took 0.0s, 139180 effective words/s
2019-03-29 01:23:46,456 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 01:23:46,457 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 01:23:46,466 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 01:23:46,467 - INFO - EPOCH - 5 : training on 4050 raw words (1615 effective words) took 0.0s, 138942 effective words/s
2019-03-29 01:23:46,468 - INFO - training on a 20250 raw words (7963 effective words) took 0.1s, 103954 effective words/s
2019-03-29 01:23:46,469 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-03-29 01:23:46,475 - INFO - Reading data done!
2019-03-29 01:23:46,569 - INFO - MODEL HAS 10364933 params
2019-03-29 01:23:46,615 - INFO - Computing model performance on validation data ...
2019-03-29 01:23:46,616 - INFO - Finished decoding data: 0/500 ...
2019-03-29 01:23:46,620 - INFO - precomputing L2-norms of doc weight vectors
2019-03-29 01:34:15,043 - INFO - collecting all words and their counts
2019-03-29 01:34:15,044 - INFO - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-03-29 01:34:15,046 - INFO - collected 974 word types and 500 unique tags from a corpus of 500 examples and 4178 words
2019-03-29 01:34:15,046 - INFO - Loading a fresh vocabulary
2019-03-29 01:34:15,047 - INFO - effective_min_count=5 retains 126 unique words (12% of original 974, drops 848)
2019-03-29 01:34:15,048 - INFO - effective_min_count=5 leaves 2956 word corpus (70% of original 4178, drops 1222)
2019-03-29 01:34:15,049 - INFO - deleting the raw counts dictionary of 974 items
2019-03-29 01:34:15,050 - INFO - sample=0.001 downsamples 78 most-common words
2019-03-29 01:34:15,050 - INFO - downsampling leaves estimated 1196 word corpus (40.5% of prior 2956)
2019-03-29 01:34:15,051 - INFO - estimated required memory for 126 words and 100 dimensions: 463800 bytes
2019-03-29 01:34:15,052 - INFO - resetting layer weights
2019-03-29 01:34:15,066 - INFO - training model with 3 workers on 126 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2019-03-29 01:34:15,070 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 01:34:15,071 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 01:34:15,080 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 01:34:15,081 - INFO - EPOCH - 1 : training on 4178 raw words (1709 effective words) took 0.0s, 154795 effective words/s
2019-03-29 01:34:15,083 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 01:34:15,084 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 01:34:15,092 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 01:34:15,093 - INFO - EPOCH - 2 : training on 4178 raw words (1665 effective words) took 0.0s, 171007 effective words/s
2019-03-29 01:34:15,095 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 01:34:15,096 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 01:34:15,105 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 01:34:15,105 - INFO - EPOCH - 3 : training on 4178 raw words (1709 effective words) took 0.0s, 164452 effective words/s
2019-03-29 01:34:15,108 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 01:34:15,109 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 01:34:15,117 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 01:34:15,117 - INFO - EPOCH - 4 : training on 4178 raw words (1660 effective words) took 0.0s, 170614 effective words/s
2019-03-29 01:34:15,120 - INFO - worker thread finished; awaiting finish of 2 more threads
2019-03-29 01:34:15,121 - INFO - worker thread finished; awaiting finish of 1 more threads
2019-03-29 01:34:15,130 - INFO - worker thread finished; awaiting finish of 0 more threads
2019-03-29 01:34:15,130 - INFO - EPOCH - 5 : training on 4178 raw words (1688 effective words) took 0.0s, 158993 effective words/s
2019-03-29 01:34:15,131 - INFO - training on a 20890 raw words (8431 effective words) took 0.1s, 130935 effective words/s
2019-03-29 01:34:15,131 - WARNING - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
2019-03-29 01:34:15,136 - INFO - Reading data done!
2019-03-29 01:34:15,318 - INFO - MODEL HAS 10364933 params
2019-03-29 01:34:21,103 - INFO - Computing model performance on validation data ...
2019-03-29 01:34:21,104 - INFO - Finished decoding data: 0/500 ...
2019-03-29 01:34:21,106 - INFO - precomputing L2-norms of doc weight vectors
2019-03-29 01:34:43,636 - INFO - Finished decoding data: 100/500 ...
2019-03-29 01:35:05,655 - INFO - Finished decoding data: 200/500 ...
2019-03-29 01:35:27,397 - INFO - Finished decoding data: 300/500 ...
2019-03-29 01:35:49,326 - INFO - Finished decoding data: 400/500 ...
2019-03-29 01:36:09,046 - INFO - eval_precision: 0.022968
2019-03-29 01:36:09,047 - INFO - eval_recall: 0.047952
2019-03-29 01:36:09,048 - INFO - eval_edit_distance: 4.830000
2019-03-29 01:36:09,048 - INFO - eval_rouge: 0.332797
